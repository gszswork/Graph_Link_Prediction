{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Dst</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.282119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.370293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.730570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Src  Dst    Weight\n",
       "0    0    1  0.043591\n",
       "1    0    2  0.282119\n",
       "2    0    3  0.370293\n",
       "3    0    4  0.730570\n",
       "4    0    5  0.821187"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "urllib.request.urlretrieve(\n",
    "    'https://data.dgl.ai/tutorial/dataset/members.csv', './members.csv')\n",
    "urllib.request.urlretrieve(\n",
    "    'https://data.dgl.ai/tutorial/dataset/interactions.csv', './interactions.csv')\n",
    "\n",
    "members = pd.read_csv('./members.csv')\n",
    "members.head()\n",
    "\n",
    "interactions = pd.read_csv('./interactions.csv')\n",
    "interactions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([44, 37, 37, 40, 30, 32, 36, 47, 35, 37, 35, 46, 46, 48, 41, 49, 46, 38,\n",
      "        44, 41, 48, 34, 43, 41, 40, 34, 38, 42, 42, 44, 48, 41, 35, 46])\n",
      "tensor([0.0436, 0.2821, 0.3703, 0.7306, 0.8212, 0.0592, 0.1290, 0.5208, 0.9413,\n",
      "        0.8049, 0.5622, 0.1401, 0.3370, 0.0937, 0.1479, 0.5500, 0.5330, 0.8024,\n",
      "        0.5267, 0.2724, 0.8261, 0.8021, 0.5614, 0.7074, 0.4958, 0.0016, 0.7004,\n",
      "        0.9994, 0.8923, 0.5914, 0.7833, 0.0370, 0.3245, 0.2271, 0.4633, 0.2147,\n",
      "        0.2377, 0.7345, 0.1060, 0.0365, 0.1786, 0.0978, 0.6268, 0.5527, 0.9900,\n",
      "        0.9305, 0.9693, 0.6085, 0.2851, 0.7237, 0.8807, 0.3584, 0.4228, 0.5872,\n",
      "        0.4046, 0.4230, 0.2269, 0.2452, 0.9186, 0.7828, 0.6702, 0.9842, 0.6230,\n",
      "        0.8770, 0.7705, 0.0792, 0.2061, 0.1296, 0.2526, 0.0133, 0.3873, 0.9578,\n",
      "        0.3104, 0.6005, 0.9137, 0.9917, 0.6545, 0.9800, 0.0474, 0.6714, 0.7191,\n",
      "        0.5558, 0.3882, 0.2935, 0.2078, 0.0057, 0.2992, 0.8579, 0.1052, 0.1317,\n",
      "        0.8670, 0.2297, 0.1604, 0.0749, 0.8305, 0.5858, 0.6224, 0.5720, 0.8557,\n",
      "        0.0430, 0.4986, 0.3251, 0.3364, 0.1713, 0.9562, 0.3600, 0.0905, 0.3536,\n",
      "        0.0079, 0.9786, 0.3352, 0.2469, 0.6525, 0.4777, 0.2314, 0.6479, 0.2787,\n",
      "        0.2849, 0.4231, 0.0133, 0.4731, 0.7927, 0.9382, 0.3341, 0.9434, 0.5147,\n",
      "        0.8111, 0.5225, 0.4876, 0.0933, 0.1534, 0.0896, 0.0354, 0.9426, 0.7184,\n",
      "        0.5440, 0.1311, 0.3717, 0.3052, 0.3453, 0.0420, 0.6364, 0.5368, 0.2863,\n",
      "        0.8324, 0.7523, 0.2304, 0.7690, 0.0144, 0.1602, 0.3883, 0.2913, 0.8517,\n",
      "        0.9825, 0.3305, 0.2510], dtype=torch.float64)\n",
      "Graph(num_nodes=34, num_edges=156,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class KarateClubDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='karate_club')\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv('./members.csv')\n",
    "        edges_data = pd.read_csv('./interactions.csv')\n",
    "        node_features = torch.from_numpy(nodes_data['Age'].to_numpy())\n",
    "        print(node_features)\n",
    "        node_labels = torch.from_numpy(nodes_data['Club'].astype('category').cat.codes.to_numpy())\n",
    "        edge_features = torch.from_numpy(edges_data['Weight'].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data['Src'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['Dst'].to_numpy())\n",
    "        print(edge_features)\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = node_features\n",
    "        self.graph.ndata['label'] = node_labels\n",
    "        self.graph.edata['weight'] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train:n_train + n_val] = True\n",
    "        test_mask[n_train + n_val:] = True\n",
    "        self.graph.ndata['train_mask'] = train_mask\n",
    "        self.graph.ndata['val_mask'] = val_mask\n",
    "        self.graph.ndata['test_mask'] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "dataset = KarateClubDataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59294\n",
      "16085\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "with open('./graphvite/data/edges.txt', 'r') as f:\n",
    "    edges = f.readlines()\n",
    "    for line in edges:\n",
    "        line = line[:len(line)-1]\n",
    "    #print(len(edges))\n",
    "    \n",
    "edge_tuple_list = []\n",
    "for line in edges:\n",
    "    source, sink = line.split(\" \")\n",
    "    edge_tuple_list.append((int(source), int(sink)))\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edge_tuple_list)\n",
    "print(len(edge_tuple_list))\n",
    "print(len(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16085\n"
     ]
    }
   ],
   "source": [
    "print(len(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3816, num_edges=32119,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n"
     ]
    }
   ],
   "source": [
    "nodes_list = list(G.nodes)\n",
    "print(nodes_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3816, 4093)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_matrix = np.zeros((3816, 4093))\n",
    "print(feature_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(nodes_list)):\n",
    "    #print(nodes_list[idx])\n",
    "    feature_matrix[idx][nodes_list[idx]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "graph.ndata['feat'] = torch.tensor(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3816, 4093])\n"
     ]
    }
   ],
   "source": [
    "print(graph.ndata['feat'].shape)\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges() // 2)\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "#pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 2.2543563318322413e-05\n",
      "In epoch 5, loss: 0.0005897232331335545\n",
      "In epoch 10, loss: 0.000199247631826438\n",
      "In epoch 15, loss: 0.0005901537369936705\n",
      "In epoch 20, loss: 8.533140498911962e-05\n",
      "In epoch 25, loss: 3.924851989722811e-05\n",
      "In epoch 30, loss: 4.098360659554601e-05\n",
      "In epoch 35, loss: 4.3439391447464004e-05\n",
      "In epoch 40, loss: 3.518634184729308e-05\n",
      "In epoch 45, loss: 2.4735683837207034e-05\n",
      "In epoch 50, loss: 1.82808144018054e-05\n",
      "In epoch 55, loss: 1.4667443792859558e-05\n",
      "In epoch 60, loss: 1.2528727893368341e-05\n",
      "In epoch 65, loss: 1.1160030226164963e-05\n",
      "In epoch 70, loss: 1.0218993338639848e-05\n",
      "In epoch 75, loss: 9.525849236524664e-06\n",
      "In epoch 80, loss: 8.991590220830403e-06\n",
      "In epoch 85, loss: 8.567641998524778e-06\n",
      "In epoch 90, loss: 8.222795258916449e-06\n",
      "In epoch 95, loss: 7.933307642815635e-06\n",
      "AUC 0.8469432402686373\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "# Thumbnail Courtesy: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
