{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"baseline model_Neural Network on Graph Features.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gvqAMopZzLCk"},"source":["### 简明的概述\r\n","\r\n","1. 读取train.txt 中存在的边，加入到NETWOKX 构建的graph（无向图）中。无向图中所有的边都视为真数据（positive data）\r\n","2. 根据无向图中的点，随机抓取两个点构成一条边，如果该边在图中不存在，则视为伪数据（negative data）,抓取出和真数据数量一致的伪数据\r\n","3. 从图中提取真伪数据的特征（各种图特征），组成训练数据，然后训练一个3层的Neural Networks。\r\n","4. 把test中的点从图中提取特征，用Neural Network 预测。\r\n","\r\n","Note：这里有一个trick，就是为了训练的点不是乱选的，所有参与训练的边，至少有一个点是从test_data中出现的。这是一个出于直觉的设计，并没有验证时一定有用的。\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xr5Oj7HLpjpu","executionInfo":{"status":"ok","timestamp":1616076248275,"user_tz":-660,"elapsed":19396,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"399fad17-54be-4bd6-d98c-1914711a74a8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10hUXyBnpsAU","executionInfo":{"status":"ok","timestamp":1616076295883,"user_tz":-660,"elapsed":747,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"bb66f10d-c984-47c8-d78c-50a6c7ee7aa5"},"source":["cd drive/MyDrive/Colab\\ Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtGbU38tpZZA","executionInfo":{"status":"ok","timestamp":1616076299307,"user_tz":-660,"elapsed":1789,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"fef16b6b-06c6-4418-d517-3f6b6f5dba1f"},"source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import scipy.sparse as sp\n","import numpy as np\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import average_precision_score\n","import pickle\n","import math\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import scipy.sparse as sp\n","import numpy as np\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import average_precision_score\n","import pickle\n","import math\n","import pandas as pd\n","import pickle\n","import math\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model.logistic import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_score, recall_score, accuracy_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","# 读写操作\n","dirname = 'data/'\n","def save_obj(obj, name ):\n","    with open(dirname+ name + '.pkl', 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(name ):\n","    with open( dirname + name + '.pkl', 'rb') as f:\n","        return pickle.load(f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qCAqZDWypZZB"},"source":["# train.TXT中有9130行数据，但是存在很多重复的点，去除重复后只有3767个点和32068条边"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-QewBR7pZZB","executionInfo":{"status":"ok","timestamp":1616076304490,"user_tz":-660,"elapsed":1035,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"f0cd38d4-15b8-4c42-a77c-638e45d0b9be"},"source":["from tqdm import tqdm\n","import random\n","\n","# 读取train.txt file\n","with open(\"data/train.txt\", \"r\") as f:\n","     train_data = f.readlines()\n","# SourceNodes 是全部的起点，Nodes和Edges是全部的点和边\n","SourceNodes = []\n","Nodes = []\n","Edges = []\n","for i in tqdm(range(len(train_data))):\n","    nodes_list = [int(n) for n in train_data[i].split()]\n","    SourceNodes.append(nodes_list[0])\n","    for node in nodes_list:\n","        Nodes.append(node)\n","    for source in nodes_list:\n","        for sink in nodes_list:\n","            if source!=sink:\n","                Edges.append((source, sink))\n","# 生成Nodes和Edges，直接从train.txt 读取就可以"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 9310/9310 [00:00<00:00, 230217.14it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28dCgP0apZZC","executionInfo":{"status":"ok","timestamp":1616076307328,"user_tz":-660,"elapsed":754,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"ebf0949b-10b5-42c6-e3af-eed59b0069be"},"source":["print(\"Before removing duplicates, we have: \")\n","print('Nodes: ',len(Nodes),'\\tEdges:', len(Edges))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Before removing duplicates, we have: \n","Nodes:  25037 \tEdges: 59236\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"7WhaiCqcpZZC","executionInfo":{"status":"ok","timestamp":1616076309659,"user_tz":-660,"elapsed":716,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"c5570177-c9c5-4f9b-cfae-3999447a75fd"},"source":["setofEdges = set(Edges)\n","setofNodes = set(Nodes)\n","print(\"After removing duplicates, we have: \")\n","print('Nodes: ',len(setofNodes),'\\tEdges:', len(setofEdges))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After removing duplicates, we have: \n","Nodes:  3767 \tEdges: 32068\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWTeC1BzpZZC","executionInfo":{"status":"ok","timestamp":1616076311602,"user_tz":-660,"elapsed":724,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"27e00573-9065-498a-c2fc-9e8e98dff99b"},"source":["# 生成正面数据\n","\n","'''\n","Edges就32068条，全部作为正面数据好了\n","\n","'''\n","pos_data = []\n","for elem in tqdm(setofEdges):\n","    pos_data.append([(elem[0], elem[1]), 1])\n","\n","print(len(pos_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 32068/32068 [00:00<00:00, 379199.84it/s]"],"name":"stderr"},{"output_type":"stream","text":["32068\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXW2ClBxpZZC","executionInfo":{"status":"ok","timestamp":1616076344816,"user_tz":-660,"elapsed":31857,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"4659aa19-050c-4038-aaa2-9a10bc02ab0a"},"source":["# 生成负面数据\n","\n","neg_data = []\n","for source in tqdm(setofNodes):\n","    for sink in random.sample(setofNodes, 3767):\n","        if source!=sink and not (source,sink) in setofEdges:\n","            neg_data.append([(source, sink), 0])\n","\n","\n","print('generated ',len(neg_data),' fake edges.')\n","neg_data = random.sample(neg_data, 32068)\n","print('To get the same size sample of true edges, we random pick ',len(neg_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 3767/3767 [00:29<00:00, 126.29it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["generated  14154454  fake edges.\n","To get the same size sample of true edges, we random pick  32068\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NvUvoFzppZZD","executionInfo":{"status":"ok","timestamp":1616076347644,"user_tz":-660,"elapsed":732,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"309f78f4-7eaa-42fd-9917-96c52f775975"},"source":["save_obj(pos_data, 'pos_data')\n","save_obj(neg_data, 'neg_data')\n","print(len(pos_data), len(neg_data))\n","print(len(pos_data[1]), len(neg_data[1]))\n","print(pos_data[1], neg_data[1])\n","# We set training data as the concatenation of pos_data and neg_data\n","training_edges = []\n","for i in range(32068):\n","    training_edges.append(pos_data[i])\n","    training_edges.append(neg_data[i])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32068 32068\n","2 2\n","[(19, 1917), 1] [(3947, 1600), 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6gmzPNTpZZD","executionInfo":{"status":"ok","timestamp":1616076350143,"user_tz":-660,"elapsed":728,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"a3423cf4-139f-47d9-b064-8d88fd8ca9e7"},"source":["# train.txt 文件已经读取， pos_data 和 neg_data 也已经读取\n","print('Nodes number:\\t','Edges number:')\n","print(len(setofNodes), '\\t',len(setofEdges), '\\n')\n","print('posdata_length: ', 'negdata_length:')\n","print(len(pos_data),'\\t', len(neg_data), '\\n')\n","\n","print('first 10 pieces of pos_data and neg_data:')\n","print(pos_data[:10],'\\n')\n","print(neg_data[:10])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Nodes number:\t Edges number:\n","3767 \t 32068 \n","\n","posdata_length:  negdata_length:\n","32068 \t 32068 \n","\n","first 10 pieces of pos_data and neg_data:\n","[[(1410, 1872), 1], [(19, 1917), 1], [(1073, 3626), 1], [(151, 3004), 1], [(148, 3935), 1], [(107, 3616), 1], [(3677, 2457), 1], [(1527, 3974), 1], [(1162, 92), 1], [(602, 2421), 1]] \n","\n","[[(3490, 3521), 0], [(3947, 1600), 0], [(2892, 175), 0], [(3301, 232), 0], [(2165, 3948), 0], [(2369, 881), 0], [(2289, 568), 0], [(4064, 2055), 0], [(1836, 861), 0], [(786, 2436), 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUZ7--52pZZD","executionInfo":{"status":"ok","timestamp":1616076352475,"user_tz":-660,"elapsed":717,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"4bf2463e-2dde-4592-db73-977d4fe4198c"},"source":["G = nx.Graph()\n","G.add_nodes_from(Nodes)\n","G.add_edges_from(setofEdges)\n","# Edges and Nodes are all from train.txt (pos_data)\n","print('Graph has been built!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Graph has been built!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PiSY86EFpZZD","executionInfo":{"status":"ok","timestamp":1616076354620,"user_tz":-660,"elapsed":716,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"11ed943d-e37f-4708-eb23-90f4d1db0f65"},"source":["# 保存G对象到本地\n","save_obj(G, 'graph')\n","print('graph has been saved')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["graph has been saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pjvw21hipZZE","executionInfo":{"status":"ok","timestamp":1616076356917,"user_tz":-660,"elapsed":987,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"3741c8e9-ecfd-4fb2-fb7a-ccc45aad18e7"},"source":["'''\n","接下来生成edges_of_all_test_data_related\n","\n","首先需要提取test.public 中所有的点，存储为 nodes_in_test_data\n","\n","然后根据nodes_in_test_data 生成 edges_of_all_test_nodes_related\n","'''\n","\n","with open(\"data/test-public.csv\", \"r\") as f:\n","     test_data = f.readlines()\n","\n","# 提取test_data 后删除第一行的ID\n","test_data = test_data[1:]\n","# 测试\n","for i in range(len(test_data)):\n","    test_data[i] = [int(elem) for elem in test_data[i].split(',')]\n","print(test_data[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2, 0, 2956]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8B_6WS1EpZZE","executionInfo":{"status":"ok","timestamp":1616076359169,"user_tz":-660,"elapsed":731,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"ba34841e-584f-422c-f7f4-bf6e597207d8"},"source":["# 提取test_data 中所有点\n","nodes_in_test_data = []\n","for line in test_data:\n","    source = line[1]\n","    sink = line[2]\n","    nodes_in_test_data.append(int(source))\n","    nodes_in_test_data.append(int(sink))\n","\n","\n","temp = nodes_in_test_data\n","temp_set = set(temp)\n","temp = list(temp_set)\n","nodes_in_test_data = temp\n","# 生成出nodes_in_test_data 后用hash set去重\n","# 可以发现大量点是重复的\n","print('Test data has ', len(nodes_in_test_data), 'nodes without duplicates')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test data has  2314 nodes without duplicates\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-CPBVrD_pZZE"},"source":["# 要把test中不存在于training data的点也加入到Graph中，这样才能生成完整的pre-features\n","G.add_nodes_from(nodes_in_test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECx5LUiDpZZE","executionInfo":{"status":"ok","timestamp":1616076364391,"user_tz":-660,"elapsed":813,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"48ef96cc-dc6f-4975-b0bc-d1361f785a43"},"source":["'''\n","debug: 为什么所有的边都被保存为了inbound？\n","\n","solution:  代码从trian.txt中读取了Edges，错在“直接把Edges转化为hash set 然后判断(e, node)是否存在”\n","\n","'''\n","\n","'''\n","生成pre_features: pre_features 需要包含哪些特征？\n","\n","1. neighbors number \n","2. log(nei_number)\n","3. all_neighbors\n","4. inbound\n","5. inbound_num\n","6. outbound\n","7. outboud_num\n","    \n","'''\n","pre_features = {}\n","count = 0\n","for node in tqdm(list(G.nodes)):\n","    neig = sorted(nx.all_neighbors(G, node))                          # 3\n","    num_neig = len(neig)                 # 1\n","    log_neig = (1. / math.log(num_neig+1)) if num_neig != 0 else 0    # 2\n","\n","    \n","    inbound = []\n","    outbound = []\n","    for e in list(neig):\n","        if (e,node) in setofEdges:\n","            inbound.append(e)\n","        if (node,e) in setofEdges:\n","            outbound.append(e)\n","    if len(inbound) == len(outbound):\n","        count += 1\n","    pre_features[node] = [num_neig, log_neig, neig, inbound, len(inbound), outbound, len(outbound)]\n","print(count)\n","# It's a undirectional Graph, what's the mean to differ inbound and outbound of nodes."],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 3816/3816 [00:00<00:00, 94762.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["3816\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nz34nCBEpZZF","executionInfo":{"status":"ok","timestamp":1616076367481,"user_tz":-660,"elapsed":746,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"a70b1726-b7e7-4a9b-a204-ffc92c0ca24d"},"source":["print(pre_features[1864])\n","save_obj(pre_features, 'pre_features')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 0, [], [], 0, [], 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"yep3DzKRpZZF","executionInfo":{"status":"ok","timestamp":1616076370365,"user_tz":-660,"elapsed":966,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"94153065-7b7c-4976-d11b-0f0d16f52102"},"source":["import pandas as pd\n","BasicFeatures = load_obj('pre_features')\n","# in-degree statistics\n","df = pd.DataFrame(BasicFeatures)\n","df =  df.T\n","df.rename(columns={0: 'num_of_neighbours',\n","                   1: 'log_num_of_neighbours',\n","                  2: 'list_of_neighbours',\n","                  3: 'list_of_in_neighbours',\n","                  4: 'num_of_in_neighbours',\n","                  5: 'list_of_out_neighbours',\n","                  6: 'num_of_out_neighbours'}, inplace=True)\n","df.loc[[2]]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>num_of_neighbours</th>\n","      <th>log_num_of_neighbours</th>\n","      <th>list_of_neighbours</th>\n","      <th>list_of_in_neighbours</th>\n","      <th>num_of_in_neighbours</th>\n","      <th>list_of_out_neighbours</th>\n","      <th>num_of_out_neighbours</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>24</td>\n","      <td>0.310667</td>\n","      <td>[51, 64, 585, 605, 932, 1146, 1230, 1348, 1389...</td>\n","      <td>[51, 64, 585, 605, 932, 1146, 1230, 1348, 1389...</td>\n","      <td>24</td>\n","      <td>[51, 64, 585, 605, 932, 1146, 1230, 1348, 1389...</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  num_of_neighbours  ... num_of_out_neighbours\n","2                24  ...                    24\n","\n","[1 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WTSz6KvIpZZF","executionInfo":{"status":"ok","timestamp":1616076383960,"user_tz":-660,"elapsed":2690,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"9ca2a73b-749c-43ea-bca8-0c345f51e13e"},"source":["\"\"\"\n","生成edges_of_all_test_nodes_related:\n","    思路是提取所有的训练数据的edge都是和test_data中的点相关的\n","\"\"\"\n","from tqdm import tqdm \n","edges_of_all_test_nodes_related = []\n","nodes_related = []\n","for line in tqdm(setofEdges):\n","    (node1, node2) = line\n","    if node1 in nodes_in_test_data:\n","        nodes_related.append(node1)\n","    if node2 in nodes_in_test_data:\n","        nodes_related.append(node2)\n","    if (node1 in nodes_in_test_data) or (node2 in nodes_in_test_data):\n","        edges_of_all_test_nodes_related.append((node1, node2))\n","\n","print('edges_related: ',len(edges_of_all_test_nodes_related))\n","print(edges_of_all_test_nodes_related[:10])\n","nodes_related = set(nodes_related)\n","print('\\nnodes related: ', len(nodes_related))\n","\n","save_obj(edges_of_all_test_nodes_related, 'edges_of_all_test_nodes_related')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 32068/32068 [00:02<00:00, 15433.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["edges_related:  29868\n","[(1410, 1872), (19, 1917), (1073, 3626), (151, 3004), (148, 3935), (107, 3616), (3677, 2457), (1527, 3974), (1162, 92), (602, 2421)]\n","\n","nodes related:  2265\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85DJL6HMpZZF","executionInfo":{"status":"ok","timestamp":1616076386070,"user_tz":-660,"elapsed":716,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"80e56925-4fa5-4dbb-d28b-2bf028b0bab1"},"source":["# show the format of data\n","print(len(pre_features))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3816\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3qW_T4xdpZZG"},"source":["from tqdm import tqdm\n","# Function\n","#Salton Similarity\n","def salton_similarity(node1, node2):\n","    n1 = pre_features[node1]\n","    n2 = pre_features[node2]\n","    common_neighors = list(set(n1[2]).intersection(set(n2[2])))\n","    inter = len(common_neighors)\n","    degree_out_flow = n1[6]\n","    degree_in_flow = n2[4]\n","    \n","    if inter == 0:\n","        return 0\n","    else:\n","        try:\n","            sqrt_of_degree = math.sqrt(degree_out_flow * degree_in_flow)\n","            salton = inter / sqrt_of_degree\n","            probability = 1 /(1 - math.log(salton)*0.2)\n","            return probability\n","        except:\n","            return 0\n","\n","#Cosine\n","def Cosine(Node1, Node2):\n","    n1 = pre_features[Node1]\n","    n2 = pre_features[Node2]\n","    common_neighors = list(set(n1[2]).intersection(n2[2]))\n","    lm = len(common_neighors)\n","    if lm == 0:\n","        return 0\n","    else:\n","        return (0.0+lm)/(len(n1[2])*len(n2[2]))\n","\n","def get_jaccard_coefficient(source, sink):\n","    \"\"\"\n","    in: source::Node object\n","    in: sink::Node object\n","    return: jaccard's cofficient::numeric\n","    \"\"\"\n","    # transform\n","    neighbours_of_source_list = BasicFeatures[source][2]\n","    neighbours_of_sink_list = BasicFeatures[sink][2]\n","    \n","    neigbours_set_of_source = set(neighbours_of_source_list)\n","    neigbours_set_of_sink = set(neighbours_of_sink_list)\n","    union_neighbours = neigbours_set_of_source | neigbours_set_of_sink\n","    common_neighbours = neigbours_set_of_source & neigbours_set_of_sink\n","    if len(union_neighbours)==0:\n","        return 0.0\n","    return(len(common_neighbours)/len(union_neighbours))\n","\n","def get_preferential_attachment(source, sink):\n","    # transform\n","    neighbours_of_source_list = BasicFeatures[source][2]\n","    neighbours_of_sink_list = BasicFeatures[sink][2]\n","    \n","    neigbours_set_of_source = set(neighbours_of_source_list)\n","    neigbours_set_of_sink = set(neighbours_of_sink_list)\n","    \n","    return len(neigbours_set_of_source)*len(neigbours_set_of_sink)\n","\n","def get_adamic_adar(source, sink):\n","    # transform\n","    neighbours_of_source_list = BasicFeatures[source][2]\n","    neighbours_of_sink_list = BasicFeatures[sink][2]\n","\n","    neigbours_set_of_source = set(neighbours_of_source_list)\n","    neigbours_set_of_sink = set(neighbours_of_sink_list)\n","    common_neighbours = neigbours_set_of_source & neigbours_set_of_sink\n","    # get the summation\n","    score = 0\n","    for common_node in common_neighbours:\n","        if math.log(len(BasicFeatures[common_node][2])) == 0:\n","            return 0.0\n","        score = score + 1/math.log(len(BasicFeatures[common_node][2]))\n","    return score\n","\n","def get_resource_allocation(source, sink):\n","    neighbours_of_source_list = BasicFeatures[source][2]\n","    neighbours_of_sink_list = BasicFeatures[sink][2]\n","#     print(neighbours_of_source_list)\n","#     print(neighbours_of_sink_list)\n","    neigbours_set_of_source = set(neighbours_of_source_list)\n","    neigbours_set_of_sink = set(neighbours_of_sink_list)\n","    \n","    common_neighbours = neigbours_set_of_source & neigbours_set_of_sink\n","#     print(common_neighbours)\n","    score=0\n","    for common_node in common_neighbours:\n","        # number of the neighbours of the common_node\n","        try:\n","            single_common_node_score = 1/BasicFeatures[common_node][0]\n","        except:\n","            single_common_node_score=0\n","        score = score + single_common_node_score\n","    return score\n","    \n","\n","# how similar are the outbound neighbors of source to sink\n","# either JA, PA, AA\n","def get_outbound_similarity_score(source, sink, metric):\n","    # get the outbound_node of source\n","    outbound_node_for_source_set = set(BasicFeatures[source][5])\n","    summation = 0\n","    for outbound_node_for_source in outbound_node_for_source_set:\n","        summation =summation + metric(sink,outbound_node_for_source)\n","    if len(outbound_node_for_source_set) == 0:\n","        return 0\n","    score = 1/len(outbound_node_for_source_set)*summation\n","    return score\n","\n","# either JA, PA, AA\n","def get_inbound_similarity_score(source, sink, metric):\n","    # get the inbound_node of sink\n","    inbound_node_for_sink_set = set(BasicFeatures[source][3])\n","    summation = 0\n","    for inbound_node_for_sink in inbound_node_for_sink_set:\n","        summation =summation + metric(source,inbound_node_for_sink)\n","    if len(inbound_node_for_sink_set) == 0:\n","        return 0\n","    score = 1/len(inbound_node_for_sink_set)*summation\n","    return score\n","\n","def get_common_neighbours(node1, node2):\n","    try:\n","        n1 = pre_features[node1]\n","        n2 = pre_features[node2]\n","        common_neighors = list(set(n1[2]).intersection(n2[2]))\n","        return common_neighors\n","    except:\n","        return 0\n","\n","def gen_training_df(final_edges):\n","    training_df = pd.DataFrame()\n","    for edge in tqdm(final_edges):\n","        source = edge[0][0]\n","        sink = edge[0][1]\n","        label = edge[1]\n","        salton_similarity_score = salton_similarity(source, sink)\n","        cosine = Cosine(source, sink)\n","        jaccard_coefficient = get_jaccard_coefficient(source, sink)\n","        preferential_attachment = get_preferential_attachment(source, sink)\n","        adamic_adar = get_adamic_adar(source, sink)\n","        resource_allocation = get_resource_allocation(source, sink)\n","\n","        #salton_similarity_score_out = get_outbound_similarity_score(source, sink, salton_similarity)\n","        cosine_out = get_outbound_similarity_score(source, sink, Cosine)\n","        jaccard_coefficient_out = get_outbound_similarity_score(source, sink, get_jaccard_coefficient)\n","        #preferential_attachment_out = get_outbound_similarity_score(source, sink, get_preferential_attachment)\n","        #adamic_adar_out = get_outbound_similarity_score(source, sink, get_adamic_adar)\n","        #resource_allocation_out = get_outbound_similarity_score(source, sink, get_resource_allocation)\n","        \n","        \n","        #salton_similarity_score_in = get_inbound_similarity_score(source, sink, salton_similarity)\n","        cosine_in = get_inbound_similarity_score(source, sink, Cosine)\n","        jaccard_coefficient_in = get_inbound_similarity_score(source, sink, get_jaccard_coefficient)\n","        #preferential_attachment_in = get_inbound_similarity_score(source, sink, get_preferential_attachment)\n","        #adamic_adar_in = get_inbound_similarity_score(source, sink, get_adamic_adar)\n","        #resource_allocation_in = get_inbound_similarity_score(source, sink, get_resource_allocation)\n","\n","        df_row = pd.DataFrame([source, \n","                               sink, \n","                               label, \n","                               salton_similarity_score, \n","                               cosine, \n","                               jaccard_coefficient,\n","                               preferential_attachment, \n","                               adamic_adar, \n","                               resource_allocation,\n","                               #salton_similarity_score_out,\n","                               cosine_out,\n","                               jaccard_coefficient_out,\n","                               #preferential_attachment_out,\n","                               #adamic_adar_out,\n","                               #resource_allocation_out,\n","                               #salton_similarity_score_in,\n","                               cosine_in,\n","                               jaccard_coefficient_in,\n","                               #preferential_attachment_in,\n","                               #adamic_adar_in,\n","                               #resource_allocation_in                         \n","                              ]).T\n","        training_df = training_df.append(df_row)\n","    return training_df\n","\n","def gen_training_edges(num_of_edges):\n","    \"\"\"\n","    num_of_edges: number of positive edges to generate\n","    \"\"\"\n","    # generate the positive_edge\n","    ps_edges = random.sample(edges_of_all_test_nodes_related, num_of_edges)\n","    ps_edges_set = set(ps_edges)   # Here we change ps_edges to hash set to decrease the time complexity\n","    nodes = set()\n","    for edge in tqdm(ps_edges):\n","        nodes.add(edge[0])\n","        nodes.add(edge[1])\n","    # generate the negative edges\n","    count = 0\n","    final_edges=list()\n","    while count < num_of_edges:\n","        if count%1000 ==0:\n","            print(count)\n","        node1, node2 = random.sample(nodes,2)\n","        if (node1,node2) not in ps_edges_set:\n","            count += 1\n","            final_edges.append((node1,node2,0))\n","    for edge in ps_edges:\n","        final_edges.append((edge[0], edge[1], 1))\n","    return final_edges"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmA19X_vpZZI","executionInfo":{"status":"ok","timestamp":1616076392924,"user_tz":-660,"elapsed":722,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"32bc1f15-ee98-4efe-d048-4fe8e61782db"},"source":["print(len(training_edges))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["64136\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUO4AnJmpZZJ","executionInfo":{"status":"ok","timestamp":1616076513342,"user_tz":-660,"elapsed":119075,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"a264789a-82ff-4169-fb46-9c4b1fb72441"},"source":["training_df = gen_training_df(training_edges)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 64136/64136 [01:58<00:00, 541.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6rcte-HpZZJ","executionInfo":{"status":"ok","timestamp":1616076516033,"user_tz":-660,"elapsed":759,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"2af7b41b-7809-4292-95e8-34125abfde26"},"source":["save_obj(training_df, 'training_df')\n","print(training_df[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0    1410.0\n","0    3490.0\n","0      19.0\n","0    3947.0\n","0    1073.0\n","      ...  \n","0    3937.0\n","0     609.0\n","0     618.0\n","0    1618.0\n","0    2814.0\n","Name: 0, Length: 64136, dtype: float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaNKU5eNpZZJ","executionInfo":{"status":"ok","timestamp":1616076519307,"user_tz":-660,"elapsed":758,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"398436b5-c602-4e6b-96e2-8fd46203b1df"},"source":["test_edges = []\n","for elem in test_data:\n","    test_edges.append((elem[1], elem[2]))\n","\n","print(test_edges[1], 'length: ', len(test_edges))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(0, 2956) length:  2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMeUCrmApZZJ","executionInfo":{"status":"ok","timestamp":1616077516113,"user_tz":-660,"elapsed":3764,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"edb5ea3a-75d2-4b9e-9e66-8b9dc1cf5fbb"},"source":["# 感觉生成test_features 和训练函数差不多，也就是没有label，到时候注意一下\n","def gen_test_df(test_edges):\n","    test_df = pd.DataFrame()\n","    for edge in tqdm(test_edges):\n","        source = edge[0]\n","        sink = edge[1]\n","        #label = edge[2]\n","        salton_similarity_score = salton_similarity(source, sink)\n","        cosine = Cosine(source, sink)\n","        jaccard_coefficient = get_jaccard_coefficient(source, sink)\n","        preferential_attachment = get_preferential_attachment(source, sink)\n","        adamic_adar = get_adamic_adar(source, sink)\n","        resource_allocation = get_resource_allocation(source, sink)\n","\n","        salton_similarity_score_out = get_outbound_similarity_score(source, sink, salton_similarity)\n","        cosine_out = get_outbound_similarity_score(source, sink, Cosine)\n","        jaccard_coefficient_out = get_outbound_similarity_score(source, sink, get_jaccard_coefficient)\n","        preferential_attachment_out = get_outbound_similarity_score(source, sink, get_preferential_attachment)\n","        adamic_adar_out = get_outbound_similarity_score(source, sink, get_adamic_adar)\n","        resource_allocation_out = get_outbound_similarity_score(source, sink, get_resource_allocation)\n","        \n","        \n","        salton_similarity_score_in = get_inbound_similarity_score(source, sink, salton_similarity)\n","        cosine_in = get_inbound_similarity_score(source, sink, Cosine)\n","        jaccard_coefficient_in = get_inbound_similarity_score(source, sink, get_jaccard_coefficient)\n","        preferential_attachment_in = get_inbound_similarity_score(source, sink, get_preferential_attachment)\n","        adamic_adar_in = get_inbound_similarity_score(source, sink, get_adamic_adar)\n","        resource_allocation_in = get_inbound_similarity_score(source, sink, get_resource_allocation)\n","\n","        df_row = pd.DataFrame([source, \n","                               sink, \n","                               salton_similarity_score, \n","                               cosine, \n","                               jaccard_coefficient,\n","                               preferential_attachment, \n","                               adamic_adar, \n","                               resource_allocation,\n","                               #salton_similarity_score_out,\n","                               cosine_out,\n","                               jaccard_coefficient_out,\n","                               #preferential_attachment_out,\n","                               #adamic_adar_out,\n","                               #resource_allocation_out,\n","                               #salton_similarity_score_in,\n","                               cosine_in,\n","                               jaccard_coefficient_in,\n","                               #preferential_attachment_in,\n","                               #adamic_adar_in,\n","                               #resource_allocation_in                         \n","                              ]).T\n","        test_df = test_df.append(df_row)\n","    return test_df\n","\n","\n","test_df = gen_test_df(test_edges)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:03<00:00, 639.92it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"F5kREFhtpZZJ"},"source":["save_obj(test_df, 'test_df')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dar0pKMSpZZJ"},"source":["# The features for training\n","final_training_data_df = training_df.iloc[:,3:20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iz985Ww6u-Ob","executionInfo":{"status":"ok","timestamp":1616077746398,"user_tz":-660,"elapsed":726,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"68550a75-cd56-4d8b-c20e-2af3d2afb98d"},"source":["print(final_training_data_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["          3         4         5      6   ...        9         10        11        12\n","0   0.805935  0.030000  0.115385  100.0  ...  0.012950  0.305202  0.017186  0.066861\n","0   0.000000  0.000000  0.000000   28.0  ...  0.000000  0.000000  0.100000  0.169231\n","0   0.876224  0.016234  0.326087  924.0  ...  0.016404  0.270639  0.018688  0.290825\n","0   0.000000  0.000000  0.000000  261.0  ...  0.000000  0.000000  0.015010  0.155938\n","0   0.883255  0.019048  0.333333  735.0  ...  0.018075  0.209698  0.011992  0.168904\n","..       ...       ...       ...    ...  ...       ...       ...       ...       ...\n","0   0.000000  0.000000  0.000000    7.0  ...  0.000000  0.000000  0.000000  0.000000\n","0   0.932009  0.053571  0.529412  168.0  ...  0.031193  0.346134  0.035039  0.358137\n","0   0.000000  0.000000  0.000000   32.0  ...  0.000000  0.000000  0.012861  0.164511\n","0   0.790092  0.035088  0.100000   57.0  ...  0.057731  0.148440  0.023130  0.284364\n","0   0.000000  0.000000  0.000000   15.0  ...  0.000000  0.000000  0.078704  0.208528\n","\n","[64136 rows x 10 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5gS0kKa4pZZK"},"source":["# The labels for training\n","final_labels_df = training_df.iloc[:,2]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aie6W0rCpZZK"},"source":["# final_training_data_df = rescale_min_max(final_training_data_df)\n","X=final_training_data_df\n","# count=0\n","# get the data and label\n","y=final_labels_df\n","\n","from sklearn.model_selection import train_test_split\n","X_t, X_test, y_t, y_test = train_test_split(X,y)\n","x_train = X_t\n","x_test = X_test\n","y_train = y_t\n","y_test = y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"As6H2vuPpZZK","executionInfo":{"status":"ok","timestamp":1616076634872,"user_tz":-660,"elapsed":725,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"ab9dff0a-46d0-4fe3-fdcc-7d010c92673d"},"source":["print(x_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(48102, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S6Ba2dLYq3hk"},"source":["import keras\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Dropout, Activation\r\n","from keras.optimizers import SGD\r\n","import numpy as np\r\n","import pickle\r\n","import pandas as pd\r\n","import time\r\n","import csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcOb-vv7pZZK"},"source":["# x_train = np.random.random((1000, 20))\r\n","# y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\r\n","# x_test = np.random.random((100, 20))\r\n","# y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\r\n","import tensorflow as tf\r\n","model = Sequential()\r\n","model.add(Dense(32, input_dim=10, activation='sigmoid'))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(16, activation='sigmoid'))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(1, activation='sigmoid'))\r\n","\r\n","\r\n","# 选择损失函数，优化器\r\n","lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\r\n","    0.001,\r\n","    #  \r\n","    decay_steps = 1000,\r\n","    decay_rate = 1,\r\n","    staircase = False\r\n",")\r\n","def get_optimizer():\r\n","    return tf.keras.optimizers.Adam(lr_schedule)\r\n","opt = get_optimizer()\r\n","model.compile(opt,\r\n","              loss='binary_crossentropy',\r\n","              metrics=['accuracy'])\r\n","\r\n","model.fit(x_train, y_train,\r\n","          epochs=200,\r\n","          batch_size=32)\r\n","score = model.evaluate(x_test, y_test, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7ALcPPYt2QO","executionInfo":{"status":"ok","timestamp":1616077766567,"user_tz":-660,"elapsed":711,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"8b09383d-e548-4d39-8273-74c8365c1109"},"source":["test_data_df = test_df.iloc[:,2:20]\r\n","print(test_df)\r\n","print(test_data_df)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        0       1         2         3   ...        8         9         10        11\n","0      0.0  2917.0  0.000000  0.000000  ...  0.009722  0.049479  0.077691  0.554471\n","0      0.0  2956.0  0.000000  0.000000  ...  0.000000  0.000000  0.077691  0.554471\n","0      1.0  4038.0  0.000000  0.000000  ...  0.000034  0.000702  0.042457  0.646066\n","0      2.0  1848.0  0.775773  0.027778  ...  0.044080  0.117634  0.010460  0.086307\n","0      3.0   513.0  0.000000  0.000000  ...  0.000000  0.000000  0.034856  0.567946\n","..     ...     ...       ...       ...  ...       ...       ...       ...       ...\n","0   3865.0  3924.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000\n","0   3917.0  4025.0  0.000000  0.000000  ...  0.000000  0.000000  0.044608  0.077243\n","0   3922.0  3947.0  0.000000  0.000000  ...  0.000936  0.015500  0.021753  0.084510\n","0   3955.0  3987.0  0.760982  0.010811  ...  0.024145  0.087237  0.006939  0.150929\n","0   3993.0  4063.0  0.000000  0.000000  ...  0.000000  0.000000  0.047750  0.677626\n","\n","[2000 rows x 12 columns]\n","          2         3         4      5   ...        8         9         10        11\n","0   0.000000  0.000000  0.000000   56.0  ...  0.009722  0.049479  0.077691  0.554471\n","0   0.000000  0.000000  0.000000   24.0  ...  0.000000  0.000000  0.077691  0.554471\n","0   0.000000  0.000000  0.000000  496.0  ...  0.000034  0.000702  0.042457  0.646066\n","0   0.775773  0.027778  0.080000   72.0  ...  0.044080  0.117634  0.010460  0.086307\n","0   0.000000  0.000000  0.000000  391.0  ...  0.000000  0.000000  0.034856  0.567946\n","..       ...       ...       ...    ...  ...       ...       ...       ...       ...\n","0   0.000000  0.000000  0.000000    2.0  ...  0.000000  0.000000  0.000000  0.000000\n","0   0.000000  0.000000  0.000000    2.0  ...  0.000000  0.000000  0.044608  0.077243\n","0   0.000000  0.000000  0.000000  116.0  ...  0.000936  0.015500  0.021753  0.084510\n","0   0.760982  0.010811  0.053333  370.0  ...  0.024145  0.087237  0.006939  0.150929\n","0   0.000000  0.000000  0.000000   15.0  ...  0.000000  0.000000  0.047750  0.677626\n","\n","[2000 rows x 10 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HBbSHQfCus9u"},"source":["result = model.predict(test_data_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfuHMPcKvdQh","executionInfo":{"status":"ok","timestamp":1616077808963,"user_tz":-660,"elapsed":714,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"451ae649-ce03-42c1-bbbe-89db2eb2c5bd"},"source":["print(result)\r\n","save_obj(result, 'pred1')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1.8608219e-03]\n"," [6.0797250e-04]\n"," [1.7252525e-02]\n"," ...\n"," [3.2354929e-02]\n"," [9.9852729e-01]\n"," [4.8601860e-04]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bnYg7ejQvhnJ"},"source":["def nowtime():\r\n","    return time.strftime(\"%Y%m%d-%H%M\", time.localtime())\r\n","\r\n","def save_prediction_to_csv(result,filename):\r\n","    headers = ['id','Predicted']\r\n","\r\n","    with open(filename + str(nowtime()) + \".csv\", 'w', encoding = 'utf8') as f:\r\n","        f_csv = csv.writer(f)\r\n","        f_csv.writerow(headers)\r\n","        f_csv.writerows(result)\r\n","#save_prediction_to_csv(result, \"shawn_ann_v1_200epoch\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFz3dmIVwYvq","executionInfo":{"status":"ok","timestamp":1616078183830,"user_tz":-660,"elapsed":791,"user":{"displayName":"gong shuzhi","photoUrl":"","userId":"05618588835000088934"}},"outputId":"34121da5-5dc4-4995-957a-032013b22885"},"source":["ret_res = []\r\n","for i in range(1,2001):\r\n","  ret_res.append([i, result[i-1][0]])\r\n","\r\n","print(ret_res)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1, 0.0018608219], [2, 0.0006079725], [3, 0.017252525], [4, 0.99837875], [5, 0.016958572], [6, 0.050883345], [7, 0.0005948512], [8, 0.99903595], [9, 0.002192472], [10, 0.99883395], [11, 0.0009019055], [12, 0.9987178], [13, 0.0013828605], [14, 0.030999912], [15, 0.9988637], [16, 0.037259027], [17, 0.0018809625], [18, 0.99898094], [19, 0.9989466], [20, 0.9985967], [21, 0.9989466], [22, 0.01691309], [23, 0.6121665], [24, 0.047736656], [25, 0.0011801168], [26, 0.7413626], [27, 0.9971054], [28, 0.99631625], [29, 0.0032401818], [30, 0.1491696], [31, 0.003413955], [32, 0.16586813], [33, 0.6846248], [34, 0.97914314], [35, 0.0015172152], [36, 0.95891595], [37, 0.020639049], [38, 0.002399747], [39, 0.5216821], [40, 0.00063360983], [41, 0.0019537199], [42, 0.83083504], [43, 0.00052409404], [44, 0.99847573], [45, 0.0020142137], [46, 0.9989963], [47, 0.010861858], [48, 0.9990859], [49, 0.9988877], [50, 0.9989736], [51, 0.9951697], [52, 0.0014120155], [53, 0.001325199], [54, 0.0018729718], [55, 0.0022548984], [56, 0.9983512], [57, 0.80788636], [58, 0.9989513], [59, 0.99898213], [60, 0.0010390982], [61, 0.9978701], [62, 0.000748266], [63, 0.00047269446], [64, 0.00047269446], [65, 0.0018132342], [66, 0.009950999], [67, 0.017732328], [68, 0.002331007], [69, 0.0007231936], [70, 0.7558685], [71, 0.010211556], [72, 0.7835604], [73, 0.0026268624], [74, 0.99455357], [75, 0.0033302847], [76, 0.9990539], [77, 0.0047302363], [78, 0.9986707], [79, 0.00057997095], [80, 0.99899846], [81, 0.0013534745], [82, 0.9990896], [83, 0.9977857], [84, 0.12360744], [85, 0.15384407], [86, 0.9983912], [87, 0.0013627153], [88, 0.0035820345], [89, 0.0007624461], [90, 0.99905044], [91, 0.006072483], [92, 0.0010718681], [93, 0.0075142505], [94, 0.9990651], [95, 0.0010677151], [96, 0.99894327], [97, 0.022297358], [98, 0.4251633], [99, 0.001631308], [100, 0.010921204], [101, 0.00779813], [102, 0.9875443], [103, 0.9572737], [104, 0.0015394094], [105, 0.21377888], [106, 0.99892163], [107, 0.0054047923], [108, 0.00078036456], [109, 0.0010055413], [110, 0.000705252], [111, 0.05215205], [112, 0.028823951], [113, 0.0049163434], [114, 0.0017959191], [115, 0.6888965], [116, 0.0011051224], [117, 0.9936527], [118, 0.99902713], [119, 0.45166817], [120, 0.8283475], [121, 0.015070717], [122, 0.31952992], [123, 0.0026890081], [124, 0.9990281], [125, 0.001714826], [126, 0.0012289035], [127, 0.0009288998], [128, 0.01565361], [129, 0.0014087699], [130, 0.0017491742], [131, 0.6002117], [132, 0.014018225], [133, 0.014933296], [134, 0.08208191], [135, 0.00044887981], [136, 0.9990814], [137, 0.99868757], [138, 0.2417677], [139, 0.002474363], [140, 0.05560777], [141, 0.018493226], [142, 0.001937957], [143, 0.0014535893], [144, 0.9445578], [145, 0.9989643], [146, 0.9989826], [147, 0.038033277], [148, 0.99841607], [149, 0.0016286838], [150, 0.00058237195], [151, 0.9800914], [152, 0.0030867], [153, 0.038150907], [154, 0.041631885], [155, 0.99889696], [156, 0.12206748], [157, 0.0005117118], [158, 0.99906355], [159, 0.00045826746], [160, 0.99823403], [161, 0.9824185], [162, 0.7853551], [163, 0.019652395], [164, 0.0028047988], [165, 0.996407], [166, 0.57187086], [167, 0.001631308], [168, 0.05385382], [169, 0.0022815329], [170, 0.38026783], [171, 0.0008541042], [172, 0.0011818289], [173, 0.00050923513], [174, 0.0004961315], [175, 0.9974331], [176, 0.00044024605], [177, 0.00044887981], [178, 0.9990814], [179, 0.011053896], [180, 0.9832243], [181, 0.0017491742], [182, 0.00456203], [183, 0.001688592], [184, 0.045259193], [185, 0.41430855], [186, 0.97884107], [187, 0.0018804427], [188, 0.0007545581], [189, 0.0012516982], [190, 0.008533705], [191, 0.59637076], [192, 0.00062094204], [193, 0.003795833], [194, 0.0022772418], [195, 0.99904543], [196, 0.99903834], [197, 0.9989353], [198, 0.99893504], [199, 0.0049241106], [200, 0.99876666], [201, 0.9990688], [202, 0.9982772], [203, 0.0024498946], [204, 0.0010964407], [205, 0.9984987], [206, 0.8601684], [207, 0.0031738442], [208, 0.5098036], [209, 0.0022815329], [210, 0.973505], [211, 0.0013981916], [212, 0.998643], [213, 0.00091296254], [214, 0.98279953], [215, 0.0010219003], [216, 0.82818425], [217, 0.55756795], [218, 0.005302936], [219, 0.6640437], [220, 0.8906068], [221, 0.009564638], [222, 0.0016113336], [223, 0.9620939], [224, 0.0018132342], [225, 0.0060525574], [226, 0.0049981517], [227, 0.6782927], [228, 0.55722326], [229, 0.0009764527], [230, 0.71416163], [231, 0.9990577], [232, 0.999038], [233, 0.9990212], [234, 0.07613934], [235, 0.8755961], [236, 0.9990089], [237, 0.0009949314], [238, 0.9989403], [239, 0.0024745844], [240, 0.001631308], [241, 0.002209178], [242, 0.99894196], [243, 0.66985834], [244, 0.9969157], [245, 0.99663734], [246, 0.00642346], [247, 0.0014388846], [248, 0.00051873294], [249, 0.032362193], [250, 0.98376447], [251, 0.99900997], [252, 0.07290284], [253, 0.9987997], [254, 0.004775211], [255, 0.090794615], [256, 0.1295374], [257, 0.9986167], [258, 0.002028191], [259, 0.001631308], [260, 0.99907255], [261, 0.9990814], [262, 0.00044024605], [263, 0.018147731], [264, 0.052442975], [265, 0.99854714], [266, 0.9988809], [267, 0.97577924], [268, 0.0013201595], [269, 0.9978309], [270, 0.0012043414], [271, 0.011111189], [272, 0.99897575], [273, 0.2864419], [274, 0.36371145], [275, 0.0016099496], [276, 0.99907446], [277, 0.9988476], [278, 0.00069940946], [279, 0.99882656], [280, 0.14567007], [281, 0.014285761], [282, 0.98731405], [283, 0.0015903572], [284, 0.99725753], [285, 0.0013387066], [286, 0.09249392], [287, 0.0073934444], [288, 0.8558165], [289, 0.997417], [290, 0.001481101], [291, 0.0039000856], [292, 0.026447719], [293, 0.0012046478], [294, 0.99906415], [295, 0.9990796], [296, 0.001631308], [297, 0.99898094], [298, 0.9982754], [299, 0.99905604], [300, 0.99905056], [301, 0.99893886], [302, 0.99904436], [303, 0.7383321], [304, 0.025205953], [305, 0.9988555], [306, 0.9988876], [307, 0.15743312], [308, 0.14366494], [309, 0.99903], [310, 0.001631308], [311, 0.00049524126], [312, 0.999089], [313, 0.001513811], [314, 0.010625554], [315, 0.044992447], [316, 0.99908173], [317, 0.0017491742], [318, 0.003638603], [319, 0.0012833482], [320, 0.035935123], [321, 0.004222295], [322, 0.00085093005], [323, 0.0005871735], [324, 0.0010013398], [325, 0.0014376808], [326, 0.0026950021], [327, 0.64826876], [328, 0.0024892362], [329, 0.009136953], [330, 0.0017755876], [331, 0.050322738], [332, 0.012465857], [333, 0.011113667], [334, 0.99894005], [335, 0.05332242], [336, 0.9983701], [337, 0.93669397], [338, 0.012213643], [339, 0.0015544951], [340, 0.68346065], [341, 0.0025234062], [342, 0.878925], [343, 0.012599712], [344, 0.010961928], [345, 0.0034877718], [346, 0.9704086], [347, 0.0006214429], [348, 0.7132907], [349, 0.0015970675], [350, 0.94593537], [351, 0.001631308], [352, 0.0017491742], [353, 0.00051842746], [354, 0.0005669268], [355, 0.030953746], [356, 0.9990527], [357, 0.0018367699], [358, 0.007984633], [359, 0.0019224097], [360, 0.0031048479], [361, 0.001869897], [362, 0.99905795], [363, 0.99907327], [364, 0.00047109355], [365, 0.014120197], [366, 0.0015771489], [367, 0.0008833442], [368, 0.11770416], [369, 0.08596023], [370, 0.929397], [371, 0.0006507163], [372, 0.0006507163], [373, 0.017237308], [374, 0.0005343571], [375, 0.0005343571], [376, 0.0035713352], [377, 0.9988464], [378, 0.0012321033], [379, 0.00057678326], [380, 0.001979796], [381, 0.99898297], [382, 0.0024519826], [383, 0.10376426], [384, 0.9986884], [385, 0.005385344], [386, 0.098537244], [387, 0.9974362], [388, 0.007933594], [389, 0.9988973], [390, 0.9989864], [391, 0.0007276262], [392, 0.9813565], [393, 0.0006357542], [394, 0.8351273], [395, 0.99884975], [396, 0.95826834], [397, 0.0038746344], [398, 0.9836141], [399, 0.5993083], [400, 0.001631308], [401, 0.012405096], [402, 0.0006578317], [403, 0.049205568], [404, 0.0019146121], [405, 0.99893194], [406, 0.003249875], [407, 0.0017419776], [408, 0.0024745844], [409, 0.99898094], [410, 0.020158794], [411, 0.9981481], [412, 0.0022634345], [413, 0.0016366163], [414, 0.9990501], [415, 0.0011942561], [416, 0.9982774], [417, 0.9989415], [418, 0.0017504408], [419, 0.0010657051], [420, 0.7157991], [421, 0.0015026396], [422, 0.095297284], [423, 0.0019592375], [424, 0.0011075152], [425, 0.9989378], [426, 0.9989176], [427, 0.033250988], [428, 0.0054341517], [429, 0.001631308], [430, 0.051996853], [431, 0.003041721], [432, 0.9831398], [433, 0.0061330907], [434, 0.9593016], [435, 0.99881256], [436, 0.79425144], [437, 0.88372093], [438, 0.08744166], [439, 0.99600995], [440, 0.09698001], [441, 0.9987753], [442, 0.00089008425], [443, 0.8173124], [444, 0.018949099], [445, 0.009826594], [446, 0.0015922354], [447, 0.9990435], [448, 0.0020325524], [449, 0.0015771489], [450, 0.025854992], [451, 0.0009879171], [452, 0.0952147], [453, 0.633736], [454, 0.0021011264], [455, 0.0073946863], [456, 0.001338743], [457, 0.6920121], [458, 0.99905866], [459, 0.026122006], [460, 0.881564], [461, 0.9990711], [462, 0.97190183], [463, 0.98629564], [464, 0.00093428715], [465, 0.9524156], [466, 0.0045217965], [467, 0.001631308], [468, 0.021784453], [469, 0.0008400768], [470, 0.00091943226], [471, 0.0008072194], [472, 0.0005024028], [473, 0.0015771489], [474, 0.9989248], [475, 0.12223696], [476, 0.027717307], [477, 0.9968817], [478, 0.037164077], [479, 0.0017491742], [480, 0.060802933], [481, 0.9988896], [482, 0.9528888], [483, 0.17325641], [484, 0.0013519736], [485, 0.0018809625], [486, 0.021628909], [487, 0.99858785], [488, 0.0031734854], [489, 0.0007153977], [490, 0.0062792385], [491, 0.99908304], [492, 0.5472253], [493, 0.99816006], [494, 0.99648607], [495, 0.0012340766], [496, 0.0015771489], [497, 0.7184773], [498, 0.034903686], [499, 0.0015499272], [500, 0.0012730435], [501, 0.99894994], [502, 0.06724623], [503, 0.0011634761], [504, 0.997973], [505, 0.03936678], [506, 0.99901974], [507, 0.7832085], [508, 0.01752837], [509, 0.94973046], [510, 0.9716722], [511, 0.0027061093], [512, 0.050887372], [513, 0.0013165339], [514, 0.9770552], [515, 0.9990459], [516, 0.6544632], [517, 0.9675181], [518, 0.0503936], [519, 0.08594464], [520, 0.7896596], [521, 0.06734134], [522, 0.03416098], [523, 0.9984944], [524, 0.0029155307], [525, 0.0007654571], [526, 0.00061554374], [527, 0.0008589677], [528, 0.001631308], [529, 0.0018132342], [530, 0.0018809625], [531, 0.009695882], [532, 0.025595106], [533, 0.0012482693], [534, 0.004869469], [535, 0.617215], [536, 0.9986621], [537, 0.99687237], [538, 0.0010154534], [539, 0.0031978306], [540, 0.60309243], [541, 0.8124515], [542, 0.0012838348], [543, 0.0196511], [544, 0.01881734], [545, 0.030616548], [546, 0.98855686], [547, 0.99711883], [548, 0.65369594], [549, 0.9989312], [550, 0.63509667], [551, 0.0045217965], [552, 0.0021774233], [553, 0.05067324], [554, 0.0064972425], [555, 0.00081788294], [556, 0.9989329], [557, 0.9990694], [558, 0.99907124], [559, 0.05445567], [560, 0.9988877], [561, 0.00054939435], [562, 0.0008185496], [563, 0.9990646], [564, 0.99858826], [565, 0.0260652], [566, 0.9979755], [567, 0.86470807], [568, 0.6894859], [569, 0.9987363], [570, 0.0047231903], [571, 0.9988154], [572, 0.0040229727], [573, 0.94112325], [574, 0.99897337], [575, 0.016042465], [576, 0.0023083582], [577, 0.00093184813], [578, 0.00077062356], [579, 0.003459167], [580, 0.052961793], [581, 0.9982938], [582, 0.014122546], [583, 0.9987445], [584, 0.001688592], [585, 0.9989153], [586, 0.9866811], [587, 0.0006708152], [588, 0.0005331208], [589, 0.00062263035], [590, 0.0027047817], [591, 0.0015540001], [592, 0.008807545], [593, 0.08146773], [594, 0.002192472], [595, 0.0017491742], [596, 0.01644014], [597, 0.007828586], [598, 0.05035404], [599, 0.0029136823], [600, 0.7106142], [601, 0.01230245], [602, 0.0006764772], [603, 0.9661316], [604, 0.0025794206], [605, 0.0012576322], [606, 0.045414288], [607, 0.0006672866], [608, 0.0019365288], [609, 0.0014576161], [610, 0.99496186], [611, 0.99874616], [612, 0.0005632924], [613, 0.0005317795], [614, 0.0028047988], [615, 0.0020865302], [616, 0.0009577095], [617, 0.0009709593], [618, 0.7763031], [619, 0.0018132342], [620, 0.9987625], [621, 0.99893254], [622, 0.9988527], [623, 0.9989512], [624, 0.0025310281], [625, 0.0021080943], [626, 0.0018132342], [627, 0.002299445], [628, 0.015798286], [629, 0.9989774], [630, 0.9988715], [631, 0.44007102], [632, 0.06384588], [633, 0.99898154], [634, 0.0029091726], [635, 0.9410696], [636, 0.0009961806], [637, 0.0015771489], [638, 0.9641591], [639, 0.8241332], [640, 0.07946826], [641, 0.0016535352], [642, 0.008336763], [643, 0.0038796177], [644, 0.99893314], [645, 0.5002246], [646, 0.0011536612], [647, 0.001631308], [648, 0.9990963], [649, 0.0015327937], [650, 0.0009747397], [651, 0.0065279333], [652, 0.9990397], [653, 0.0009258082], [654, 0.001631308], [655, 0.04132445], [656, 0.0041086627], [657, 0.0007860452], [658, 0.005176996], [659, 0.99537474], [660, 0.002719385], [661, 0.0006196012], [662, 0.010159242], [663, 0.0028345278], [664, 0.0012459009], [665, 0.0019769678], [666, 0.10477335], [667, 0.00940842], [668, 0.0009050994], [669, 0.99775], [670, 0.9990025], [671, 0.0045217965], [672, 0.00053247495], [673, 0.4136188], [674, 0.0017632699], [675, 0.053397015], [676, 0.0056493287], [677, 0.00913014], [678, 0.0023433352], [679, 0.0029103195], [680, 0.001631308], [681, 0.8098446], [682, 0.009002288], [683, 0.0014195876], [684, 0.7661007], [685, 0.99883693], [686, 0.5879772], [687, 0.0018051397], [688, 0.9977658], [689, 0.038046513], [690, 0.0062004398], [691, 0.0018132342], [692, 0.0017373046], [693, 0.61233747], [694, 0.001070614], [695, 0.0057965084], [696, 0.00088196533], [697, 0.036496006], [698, 0.014526423], [699, 0.75798815], [700, 0.001631308], [701, 0.010507696], [702, 0.6127053], [703, 0.9684277], [704, 0.00097627455], [705, 0.0008716874], [706, 0.00044024605], [707, 0.001631308], [708, 0.025627818], [709, 0.0012176625], [710, 0.0024023217], [711, 0.0008607404], [712, 0.006103272], [713, 0.998432], [714, 0.0018809625], [715, 0.001688592], [716, 0.0007673655], [717, 0.039383516], [718, 0.016335683], [719, 0.002019846], [720, 0.00062921055], [721, 0.001688592], [722, 0.0014519098], [723, 0.99871576], [724, 0.9985067], [725, 0.9989723], [726, 0.01669545], [727, 0.84458745], [728, 0.003570516], [729, 0.0032972284], [730, 0.001631308], [731, 0.012206396], [732, 0.0059976513], [733, 0.0014171805], [734, 0.008814266], [735, 0.047108926], [736, 0.0031165385], [737, 0.0020910266], [738, 0.024339305], [739, 0.0006834897], [740, 0.0012598826], [741, 0.14158453], [742, 0.9288281], [743, 0.029320046], [744, 0.0008116025], [745, 0.00096732413], [746, 0.0005751221], [747, 0.007237117], [748, 0.9298887], [749, 0.9886774], [750, 0.0037300703], [751, 0.003070777], [752, 0.99858665], [753, 0.82830733], [754, 0.031037673], [755, 0.0043647294], [756, 0.9986204], [757, 0.98892164], [758, 0.013085605], [759, 0.0024943054], [760, 0.99869305], [761, 0.9990062], [762, 0.99251467], [763, 0.9983846], [764, 0.0016483103], [765, 0.0034608208], [766, 0.15250275], [767, 0.9875443], [768, 0.9892924], [769, 0.9988865], [770, 0.003931174], [771, 0.9983911], [772, 0.48552975], [773, 0.0019733177], [774, 0.0028195998], [775, 0.9985733], [776, 0.0028725732], [777, 0.9989417], [778, 0.0029445032], [779, 0.9990559], [780, 0.0024543363], [781, 0.02049226], [782, 0.013154216], [783, 0.028284796], [784, 0.9988569], [785, 0.9990601], [786, 0.99908435], [787, 0.008586849], [788, 0.001688592], [789, 0.057241224], [790, 0.001631308], [791, 0.008961881], [792, 0.014036408], [793, 0.9986702], [794, 0.9824638], [795, 0.9986706], [796, 0.0015686258], [797, 0.0018799586], [798, 0.99898916], [799, 0.99898916], [800, 0.002028191], [801, 0.001631308], [802, 0.0047231903], [803, 0.9976165], [804, 0.14028214], [805, 0.9941863], [806, 0.9956689], [807, 0.9979533], [808, 0.16756934], [809, 0.9658469], [810, 0.0047767838], [811, 0.005855895], [812, 0.9606399], [813, 0.8238245], [814, 0.0007366447], [815, 0.9989397], [816, 0.99896944], [817, 0.04660201], [818, 0.9986481], [819, 0.03360663], [820, 0.063385926], [821, 0.960776], [822, 0.8752207], [823, 0.9920621], [824, 0.006015904], [825, 0.99892825], [826, 0.040281855], [827, 0.006010685], [828, 0.014768518], [829, 0.82036644], [830, 0.0005632924], [831, 0.0009816973], [832, 0.0011878104], [833, 0.99895394], [834, 0.6417131], [835, 0.0055161677], [836, 0.0013996876], [837, 0.0017601092], [838, 0.001631308], [839, 0.0024155108], [840, 0.984906], [841, 0.017627627], [842, 0.84242797], [843, 0.091999], [844, 0.0015374478], [845, 0.0006440004], [846, 0.0037172365], [847, 0.99908984], [848, 0.0041317465], [849, 0.6723103], [850, 0.0018809625], [851, 0.67593634], [852, 0.007203708], [853, 0.0009651764], [854, 0.0018549416], [855, 0.0009013574], [856, 0.0005657336], [857, 0.32186413], [858, 0.0009933638], [859, 0.0010077653], [860, 0.9985903], [861, 0.02234485], [862, 0.01598272], [863, 0.0070365765], [864, 0.0011212988], [865, 0.06226669], [866, 0.9990677], [867, 0.010186481], [868, 0.8370097], [869, 0.99893814], [870, 0.9989403], [871, 0.008840834], [872, 0.99907947], [873, 0.99888223], [874, 0.99897873], [875, 0.005037531], [876, 0.051744286], [877, 0.028258044], [878, 0.99898094], [879, 0.0047231903], [880, 0.0017491742], [881, 0.9988481], [882, 0.0019805864], [883, 0.9989919], [884, 0.08724693], [885, 0.087396525], [886, 0.9968837], [887, 0.0008168689], [888, 0.0009545193], [889, 0.0019171021], [890, 0.0067374483], [891, 0.01017251], [892, 0.015300564], [893, 0.0019525477], [894, 0.9932052], [895, 0.006344805], [896, 0.0528509], [897, 0.9925937], [898, 0.0025050628], [899, 0.002051544], [900, 0.002192472], [901, 0.0022815329], [902, 0.0007655775], [903, 0.016866257], [904, 0.0019375539], [905, 0.0009246044], [906, 0.9990495], [907, 0.99789304], [908, 0.9988412], [909, 0.005771689], [910, 0.99681574], [911, 0.00045693183], [912, 0.000687492], [913, 0.001688592], [914, 0.001688592], [915, 0.0043285107], [916, 0.0018809625], [917, 0.003633438], [918, 0.99865913], [919, 0.7284931], [920, 0.9990441], [921, 0.06366022], [922, 0.0034783198], [923, 0.06907873], [924, 0.10097005], [925, 0.519099], [926, 0.9987305], [927, 0.5322657], [928, 0.99223125], [929, 0.0015771489], [930, 0.0014680093], [931, 0.0893902], [932, 0.9990814], [933, 0.0016766774], [934, 0.0016792766], [935, 0.70203936], [936, 0.009425537], [937, 0.81728226], [938, 0.0010845709], [939, 0.9602466], [940, 0.001631308], [941, 0.001631308], [942, 0.0018132342], [943, 0.0018782254], [944, 0.00044024605], [945, 0.9988852], [946, 0.017058369], [947, 0.81279117], [948, 0.035504557], [949, 0.07897668], [950, 0.12601668], [951, 0.06131974], [952, 0.6759016], [953, 0.07639804], [954, 0.9990388], [955, 0.015648158], [956, 0.011800291], [957, 0.7796113], [958, 0.008283047], [959, 0.0031436905], [960, 0.99881613], [961, 0.5151563], [962, 0.99862874], [963, 0.001804029], [964, 0.01602883], [965, 0.92475563], [966, 0.9962214], [967, 0.998811], [968, 0.049677923], [969, 0.004084534], [970, 0.9988949], [971, 0.00044050548], [972, 0.0004589556], [973, 0.9990994], [974, 0.0007017911], [975, 0.0008393843], [976, 0.99854374], [977, 0.0073752934], [978, 0.0018132342], [979, 0.001631308], [980, 0.0011407466], [981, 0.001631308], [982, 0.0470502], [983, 0.016880384], [984, 0.07769317], [985, 0.09368857], [986, 0.0010900638], [987, 0.750934], [988, 0.0008135899], [989, 0.027556848], [990, 0.99893874], [991, 0.9555614], [992, 0.010650632], [993, 0.5446703], [994, 0.99888474], [995, 0.050051097], [996, 0.99891806], [997, 0.99894017], [998, 0.39352566], [999, 0.0004831575], [1000, 0.16404623], [1001, 0.9971096], [1002, 0.5902436], [1003, 0.13922489], [1004, 0.030594455], [1005, 0.9942597], [1006, 0.9524593], [1007, 0.023212217], [1008, 0.0008314331], [1009, 0.0021833135], [1010, 0.0012349908], [1011, 0.0017875112], [1012, 0.9989403], [1013, 0.9989512], [1014, 0.00055477174], [1015, 0.0006539274], [1016, 0.0023245288], [1017, 0.001631308], [1018, 0.9980629], [1019, 0.96230435], [1020, 0.0007824831], [1021, 0.0017147543], [1022, 0.035717204], [1023, 0.05721662], [1024, 0.011394122], [1025, 0.9945551], [1026, 0.011394122], [1027, 0.99849236], [1028, 0.0009615537], [1029, 0.0015771489], [1030, 0.0027138507], [1031, 0.11363751], [1032, 0.07166939], [1033, 0.9986646], [1034, 0.001631308], [1035, 0.00065141905], [1036, 0.9990553], [1037, 0.010415527], [1038, 0.0011725053], [1039, 0.99894017], [1040, 0.99894017], [1041, 0.7829483], [1042, 0.48386812], [1043, 0.8371605], [1044, 0.006723661], [1045, 0.64462054], [1046, 0.06827695], [1047, 0.056558985], [1048, 0.99602216], [1049, 0.0012887612], [1050, 0.9988444], [1051, 0.998585], [1052, 0.9990175], [1053, 0.9988469], [1054, 0.0014333294], [1055, 0.9990301], [1056, 0.00053363584], [1057, 0.0025001597], [1058, 0.00047990965], [1059, 0.0071883784], [1060, 0.0011991353], [1061, 0.99905044], [1062, 0.99904805], [1063, 0.0016990108], [1064, 0.001631308], [1065, 0.0021080943], [1066, 0.9257384], [1067, 0.001631308], [1068, 0.0025407434], [1069, 0.7856508], [1070, 0.99908316], [1071, 0.0009819977], [1072, 0.0021080943], [1073, 0.0012289035], [1074, 0.99869484], [1075, 0.0014402563], [1076, 0.0017491742], [1077, 0.0032424496], [1078, 0.014644975], [1079, 0.06300535], [1080, 0.9989002], [1081, 0.995106], [1082, 0.0019525477], [1083, 0.0053772763], [1084, 0.0025133062], [1085, 0.0018461945], [1086, 0.99873966], [1087, 0.0007879715], [1088, 0.011076516], [1089, 0.003417792], [1090, 0.061911162], [1091, 0.015987903], [1092, 0.7738857], [1093, 0.82849246], [1094, 0.999008], [1095, 0.0008137023], [1096, 0.0567656], [1097, 0.13204025], [1098, 0.97575516], [1099, 0.99894506], [1100, 0.6851234], [1101, 0.007868662], [1102, 0.044948127], [1103, 0.0018591984], [1104, 0.044823032], [1105, 0.99895704], [1106, 0.99905175], [1107, 0.74532413], [1108, 0.0037620165], [1109, 0.00554812], [1110, 0.00064423674], [1111, 0.32642388], [1112, 0.03522555], [1113, 0.000873282], [1114, 0.0012146265], [1115, 0.9985158], [1116, 0.01766772], [1117, 0.077674], [1118, 0.0015989816], [1119, 0.042358257], [1120, 0.0015309375], [1121, 0.0063479473], [1122, 0.00976021], [1123, 0.0016330914], [1124, 0.0009799644], [1125, 0.83956504], [1126, 0.7793731], [1127, 0.024816236], [1128, 0.0015771489], [1129, 0.9969181], [1130, 0.00092643296], [1131, 0.9990132], [1132, 0.9989617], [1133, 0.09383821], [1134, 0.041037947], [1135, 0.00069970416], [1136, 0.9990814], [1137, 0.062133443], [1138, 0.025409319], [1139, 0.028051335], [1140, 0.9696302], [1141, 0.0016038006], [1142, 0.009300992], [1143, 0.00927539], [1144, 0.0051360815], [1145, 0.9974021], [1146, 0.9145901], [1147, 0.0011791033], [1148, 0.9990792], [1149, 0.0021101055], [1150, 0.9990792], [1151, 0.0026890081], [1152, 0.029673647], [1153, 0.020822974], [1154, 0.9990049], [1155, 0.9990087], [1156, 0.9988292], [1157, 0.09975088], [1158, 0.001688592], [1159, 0.99870765], [1160, 0.00068048656], [1161, 0.00106488], [1162, 0.0029502118], [1163, 0.0030073707], [1164, 0.008356204], [1165, 0.001631308], [1166, 0.9988703], [1167, 0.96052516], [1168, 0.66535753], [1169, 0.0124780955], [1170, 0.9057071], [1171, 0.021105953], [1172, 0.19297181], [1173, 0.028150821], [1174, 0.14151028], [1175, 0.9786773], [1176, 0.7870003], [1177, 0.9989366], [1178, 0.00061215804], [1179, 0.99885154], [1180, 0.0012343833], [1181, 0.99885154], [1182, 0.7275547], [1183, 0.024922565], [1184, 0.0010856481], [1185, 0.99897873], [1186, 0.0016834458], [1187, 0.0015771489], [1188, 0.0017491742], [1189, 0.92284685], [1190, 0.679038], [1191, 0.06913325], [1192, 0.04394671], [1193, 0.027309403], [1194, 0.9989874], [1195, 0.976304], [1196, 0.98565614], [1197, 0.9912178], [1198, 0.0016938306], [1199, 0.99898094], [1200, 0.0034783198], [1201, 0.4844308], [1202, 0.99908316], [1203, 0.00045780596], [1204, 0.99853957], [1205, 0.0023679682], [1206, 0.9664147], [1207, 0.42704466], [1208, 0.1193219], [1209, 0.51439273], [1210, 0.002040976], [1211, 0.002040976], [1212, 0.029653065], [1213, 0.9989938], [1214, 0.001688592], [1215, 0.0025307431], [1216, 0.0012918389], [1217, 0.0041431966], [1218, 0.007252241], [1219, 0.013135814], [1220, 0.042250235], [1221, 0.04552329], [1222, 0.010778551], [1223, 0.02957191], [1224, 0.0016763549], [1225, 0.005063089], [1226, 0.11140409], [1227, 0.6798606], [1228, 0.9986016], [1229, 0.0010700189], [1230, 0.0019525477], [1231, 0.0015771489], [1232, 0.019707933], [1233, 0.0015185783], [1234, 0.003356749], [1235, 0.99898297], [1236, 0.0006583796], [1237, 0.0027618008], [1238, 0.0016655339], [1239, 0.99206805], [1240, 0.9990227], [1241, 0.6299321], [1242, 0.009470555], [1243, 0.9666972], [1244, 0.9986325], [1245, 0.95173126], [1246, 0.0015771489], [1247, 0.00049764616], [1248, 0.9608843], [1249, 0.0018222169], [1250, 0.806222], [1251, 0.09576723], [1252, 0.0045362604], [1253, 0.0018113703], [1254, 0.05167345], [1255, 0.15607007], [1256, 0.99814916], [1257, 0.012099849], [1258, 0.0015771489], [1259, 0.9404795], [1260, 0.9989183], [1261, 0.9820801], [1262, 0.018185819], [1263, 0.0048163263], [1264, 0.011061415], [1265, 0.9987043], [1266, 0.99705744], [1267, 0.9983742], [1268, 0.003631017], [1269, 0.05213123], [1270, 0.999006], [1271, 0.99875367], [1272, 0.9989292], [1273, 0.11864184], [1274, 0.12612785], [1275, 0.024610145], [1276, 0.0011726248], [1277, 0.9980565], [1278, 0.99893326], [1279, 0.059549652], [1280, 0.02926917], [1281, 0.99886477], [1282, 0.9988456], [1283, 0.0014057504], [1284, 0.03637678], [1285, 0.98861], [1286, 0.06681753], [1287, 0.9982116], [1288, 0.011923692], [1289, 0.029581333], [1290, 0.99873346], [1291, 0.009113762], [1292, 0.99897814], [1293, 0.99846625], [1294, 0.0026890081], [1295, 0.050396938], [1296, 0.010885603], [1297, 0.0014220008], [1298, 0.011988235], [1299, 0.99895823], [1300, 0.0047043096], [1301, 0.9988518], [1302, 0.00076161063], [1303, 0.0022815329], [1304, 0.0019045387], [1305, 0.9990977], [1306, 0.0013876904], [1307, 0.0438269], [1308, 0.001631308], [1309, 0.001631308], [1310, 0.00048171493], [1311, 0.9958658], [1312, 0.0027187592], [1313, 0.055291273], [1314, 0.001631308], [1315, 0.00077157153], [1316, 0.9988047], [1317, 0.9960496], [1318, 0.078669384], [1319, 0.022802891], [1320, 0.022802891], [1321, 0.6755665], [1322, 0.9990208], [1323, 0.0015771489], [1324, 0.0015328178], [1325, 0.0015328178], [1326, 0.00315762], [1327, 0.0020195115], [1328, 0.001492661], [1329, 0.0008280697], [1330, 0.013725806], [1331, 0.040057275], [1332, 0.9989618], [1333, 0.12977844], [1334, 0.0017491742], [1335, 0.0010791611], [1336, 0.025447762], [1337, 0.003764391], [1338, 0.001340713], [1339, 0.01082414], [1340, 0.0010227292], [1341, 0.0007151499], [1342, 0.00067807315], [1343, 0.0010878926], [1344, 0.002908427], [1345, 0.99846315], [1346, 0.001445393], [1347, 0.0024745844], [1348, 0.010466177], [1349, 0.001631308], [1350, 0.0017491742], [1351, 0.0019525477], [1352, 0.04834819], [1353, 0.002192472], [1354, 0.0028047988], [1355, 0.00046401352], [1356, 0.01520962], [1357, 0.07030435], [1358, 0.0015478139], [1359, 0.0034465904], [1360, 0.003996833], [1361, 0.9983931], [1362, 0.99905974], [1363, 0.0012833482], [1364, 0.0017491742], [1365, 0.0012852405], [1366, 0.051193345], [1367, 0.998992], [1368, 0.001631308], [1369, 0.001688592], [1370, 0.0015771489], [1371, 0.6764537], [1372, 0.0018078001], [1373, 0.014827107], [1374, 0.0005521146], [1375, 0.99491787], [1376, 0.00061745016], [1377, 0.006834534], [1378, 0.9988348], [1379, 0.99895895], [1380, 0.026537312], [1381, 0.0015771489], [1382, 0.0015771489], [1383, 0.04317301], [1384, 0.6308106], [1385, 0.998689], [1386, 0.99840575], [1387, 0.99840575], [1388, 0.0007038799], [1389, 0.0025230523], [1390, 0.00065244205], [1391, 0.991859], [1392, 0.00050567224], [1393, 0.0007925399], [1394, 0.0017210861], [1395, 0.00073799765], [1396, 0.5674614], [1397, 0.0017353748], [1398, 0.004420489], [1399, 0.001631308], [1400, 0.0029266009], [1401, 0.0024272327], [1402, 0.0007949012], [1403, 0.0055315774], [1404, 0.99822336], [1405, 0.069475584], [1406, 0.0021606868], [1407, 0.05733932], [1408, 0.0020608911], [1409, 0.020442052], [1410, 0.0033535857], [1411, 0.0007513991], [1412, 0.53554046], [1413, 0.090526134], [1414, 0.9987627], [1415, 0.0019525477], [1416, 0.99908423], [1417, 0.0004541665], [1418, 0.9601532], [1419, 0.99613106], [1420, 0.009500173], [1421, 0.9852823], [1422, 0.99907494], [1423, 0.0015745583], [1424, 0.00064791273], [1425, 0.001631308], [1426, 0.026255606], [1427, 0.0009171448], [1428, 0.0007565262], [1429, 0.0011094561], [1430, 0.0049192323], [1431, 0.0044183363], [1432, 0.4633235], [1433, 0.0030029707], [1434, 0.9989593], [1435, 0.0017491742], [1436, 0.002028191], [1437, 0.0005479953], [1438, 0.98752964], [1439, 0.01714703], [1440, 0.9990963], [1441, 0.0011254766], [1442, 0.998911], [1443, 0.0010920474], [1444, 0.9990048], [1445, 0.9989505], [1446, 0.0059876847], [1447, 0.0015771489], [1448, 0.9987332], [1449, 0.000579686], [1450, 0.001688592], [1451, 0.0025790131], [1452, 0.9988961], [1453, 0.99910516], [1454, 0.006171065], [1455, 0.16363682], [1456, 0.23903684], [1457, 0.0020862978], [1458, 0.00080489856], [1459, 0.01681613], [1460, 0.7636547], [1461, 0.051398408], [1462, 0.9927939], [1463, 0.0010792685], [1464, 0.0014134154], [1465, 0.079878055], [1466, 0.9931213], [1467, 0.015154986], [1468, 0.036858562], [1469, 0.0006342113], [1470, 0.01074567], [1471, 0.0013576598], [1472, 0.964766], [1473, 0.048987683], [1474, 0.9979665], [1475, 0.0015771489], [1476, 0.002192472], [1477, 0.0010610654], [1478, 0.0015771489], [1479, 0.0045217965], [1480, 0.9990232], [1481, 0.010114697], [1482, 0.0202317], [1483, 0.99894315], [1484, 0.53160685], [1485, 0.0018920952], [1486, 0.9990005], [1487, 0.9989379], [1488, 0.998387], [1489, 0.0035775034], [1490, 0.9830562], [1491, 0.01294721], [1492, 0.062142566], [1493, 0.0010329353], [1494, 0.00080635754], [1495, 0.13555104], [1496, 0.0016702382], [1497, 0.9978472], [1498, 0.9988537], [1499, 0.1901193], [1500, 0.99662364], [1501, 0.0024745844], [1502, 0.013300707], [1503, 0.042704437], [1504, 0.0005723725], [1505, 0.99907136], [1506, 0.0015771489], [1507, 0.9990834], [1508, 0.009766503], [1509, 0.99740833], [1510, 0.9984125], [1511, 0.9990963], [1512, 0.095882446], [1513, 0.014939274], [1514, 0.9989735], [1515, 0.040845793], [1516, 0.0008943987], [1517, 0.037290674], [1518, 0.95704764], [1519, 0.0006940653], [1520, 0.016601615], [1521, 0.0016929012], [1522, 0.9989716], [1523, 0.987587], [1524, 0.00065163826], [1525, 0.0018132342], [1526, 0.0006501417], [1527, 0.001631308], [1528, 0.0029266009], [1529, 0.56839293], [1530, 0.99901164], [1531, 0.0007445222], [1532, 0.9227338], [1533, 0.06338759], [1534, 0.99872845], [1535, 0.99467504], [1536, 0.9936185], [1537, 0.0660018], [1538, 0.99903107], [1539, 0.11171046], [1540, 0.1317237], [1541, 0.041819282], [1542, 0.0036323972], [1543, 0.8294384], [1544, 0.87385], [1545, 0.0008453928], [1546, 0.0040902994], [1547, 0.0005632924], [1548, 0.0075128386], [1549, 0.11356932], [1550, 0.0015139335], [1551, 0.9209273], [1552, 0.002273013], [1553, 0.998235], [1554, 0.00082005357], [1555, 0.0031367347], [1556, 0.37914762], [1557, 0.99902797], [1558, 0.0024300977], [1559, 0.0039755236], [1560, 0.9990596], [1561, 0.0017491742], [1562, 0.007452664], [1563, 0.0042124586], [1564, 0.0005317795], [1565, 0.012822705], [1566, 0.61502105], [1567, 0.0021347345], [1568, 0.998939], [1569, 0.9987123], [1570, 0.99890673], [1571, 0.93641984], [1572, 0.0015771489], [1573, 0.0017491742], [1574, 0.015163969], [1575, 0.81968236], [1576, 0.013415007], [1577, 0.059280828], [1578, 0.070119925], [1579, 0.058333106], [1580, 0.99852896], [1581, 0.7584016], [1582, 0.99556434], [1583, 0.0014006556], [1584, 0.004957604], [1585, 0.8343329], [1586, 0.001261926], [1587, 0.096499264], [1588, 0.0018168445], [1589, 0.99846625], [1590, 0.9711031], [1591, 0.99898094], [1592, 0.0012144743], [1593, 0.0018809625], [1594, 0.0034581872], [1595, 0.92236924], [1596, 0.00089584227], [1597, 0.12226171], [1598, 0.07247351], [1599, 0.8565289], [1600, 0.58122736], [1601, 0.0018794539], [1602, 0.0029266009], [1603, 0.9989404], [1604, 0.5184469], [1605, 0.015085184], [1606, 0.0333726], [1607, 0.99237484], [1608, 0.001688592], [1609, 0.9989446], [1610, 0.0044116145], [1611, 0.99898094], [1612, 0.00040705845], [1613, 0.004397753], [1614, 0.0063691786], [1615, 0.0010355405], [1616, 0.00044742308], [1617, 0.00044742308], [1618, 0.9976107], [1619, 0.00078113127], [1620, 0.99777263], [1621, 0.99897134], [1622, 0.9989502], [1623, 0.0018809625], [1624, 0.0010914692], [1625, 0.00996872], [1626, 0.009459999], [1627, 0.0024456135], [1628, 0.8747087], [1629, 0.004927044], [1630, 0.9988292], [1631, 0.0017491742], [1632, 0.12614703], [1633, 0.9896706], [1634, 0.0046635927], [1635, 0.53555876], [1636, 0.6256643], [1637, 0.026025489], [1638, 0.0034783198], [1639, 0.04936976], [1640, 0.9989195], [1641, 0.0015224513], [1642, 0.9940164], [1643, 0.0018851167], [1644, 0.95985407], [1645, 0.0029462453], [1646, 0.0026890081], [1647, 0.99898094], [1648, 0.0015771489], [1649, 0.99907875], [1650, 0.0009118898], [1651, 0.007872556], [1652, 0.0014008831], [1653, 0.001631308], [1654, 0.001020814], [1655, 0.001688592], [1656, 0.45855063], [1657, 0.106823176], [1658, 0.0019525477], [1659, 0.0007069527], [1660, 0.9989398], [1661, 0.0018132342], [1662, 0.45094758], [1663, 0.0011508869], [1664, 0.018734872], [1665, 0.012644818], [1666, 0.025263894], [1667, 0.042661533], [1668, 0.99904996], [1669, 0.0008839348], [1670, 0.003189125], [1671, 0.99898094], [1672, 0.9986688], [1673, 0.97889256], [1674, 0.65029025], [1675, 0.7087653], [1676, 0.9803043], [1677, 0.01964949], [1678, 0.6378495], [1679, 0.009035317], [1680, 0.0019615411], [1681, 0.079469375], [1682, 0.99902344], [1683, 0.0017677011], [1684, 0.06664975], [1685, 0.9101263], [1686, 0.056089744], [1687, 0.0025571368], [1688, 0.07787846], [1689, 0.00083455566], [1690, 0.9990144], [1691, 0.01215456], [1692, 0.0017466955], [1693, 0.017382707], [1694, 0.0024745844], [1695, 0.0006860717], [1696, 0.99907196], [1697, 0.9960258], [1698, 0.9990963], [1699, 0.010493546], [1700, 0.99865985], [1701, 0.9151265], [1702, 0.7402196], [1703, 0.9571585], [1704, 0.0009091894], [1705, 0.08166114], [1706, 0.01017251], [1707, 0.978404], [1708, 0.022144727], [1709, 0.004301548], [1710, 0.99880457], [1711, 0.0017491742], [1712, 0.9990363], [1713, 0.9978703], [1714, 0.99894017], [1715, 0.010999551], [1716, 0.04325811], [1717, 0.99774617], [1718, 0.9978933], [1719, 0.9978933], [1720, 0.002600515], [1721, 0.028618582], [1722, 0.0027597698], [1723, 0.9990606], [1724, 0.0013509085], [1725, 0.9990088], [1726, 0.999067], [1727, 0.0017873087], [1728, 0.0019525477], [1729, 0.0857135], [1730, 0.0037088683], [1731, 0.66257197], [1732, 0.0012726851], [1733, 0.038105786], [1734, 0.02724191], [1735, 0.3346471], [1736, 0.04595036], [1737, 0.033851486], [1738, 0.0011934129], [1739, 0.022870291], [1740, 0.00090774], [1741, 0.043249235], [1742, 0.11516417], [1743, 0.095852174], [1744, 0.9988213], [1745, 0.0063691786], [1746, 0.0009850754], [1747, 0.001688592], [1748, 0.0017169971], [1749, 0.001631308], [1750, 0.08416104], [1751, 0.00104647], [1752, 0.009505797], [1753, 0.0022815329], [1754, 0.9981127], [1755, 0.0034783198], [1756, 0.0010809544], [1757, 0.0023699845], [1758, 0.0018132342], [1759, 0.0018664774], [1760, 0.0034186647], [1761, 0.0010872388], [1762, 0.009583412], [1763, 0.9977659], [1764, 0.0017667522], [1765, 0.00086078874], [1766, 0.07960678], [1767, 0.75595886], [1768, 0.0010330762], [1769, 0.010783083], [1770, 0.99898094], [1771, 0.99875903], [1772, 0.99901044], [1773, 0.002710367], [1774, 0.0023754982], [1775, 0.8853574], [1776, 0.0015293158], [1777, 0.81826496], [1778, 0.09524326], [1779, 0.0018809625], [1780, 0.3442566], [1781, 0.9990627], [1782, 0.0016907783], [1783, 0.001237895], [1784, 0.0020709676], [1785, 0.0009832166], [1786, 0.001631308], [1787, 0.001971708], [1788, 0.9867561], [1789, 0.9795298], [1790, 0.99010414], [1791, 0.87425286], [1792, 0.9989208], [1793, 0.015978424], [1794, 0.065968096], [1795, 0.92590666], [1796, 0.9986234], [1797, 0.02447757], [1798, 0.0022205515], [1799, 0.00080783066], [1800, 0.0019486701], [1801, 0.0024929899], [1802, 0.0008418422], [1803, 0.9775169], [1804, 0.036148082], [1805, 0.99892235], [1806, 0.99898034], [1807, 0.99549794], [1808, 0.001315738], [1809, 0.03251607], [1810, 0.0020616914], [1811, 0.0007778629], [1812, 0.060261097], [1813, 0.0012378119], [1814, 0.9989687], [1815, 0.0005479953], [1816, 0.0006014509], [1817, 0.99898094], [1818, 0.9990656], [1819, 0.006222372], [1820, 0.998629], [1821, 0.04357676], [1822, 0.06420272], [1823, 0.2807716], [1824, 0.002768338], [1825, 0.99897456], [1826, 0.4163351], [1827, 0.9990043], [1828, 0.00051321584], [1829, 0.99891436], [1830, 0.9986559], [1831, 0.650401], [1832, 0.00811816], [1833, 0.9953555], [1834, 0.9981127], [1835, 0.0015771489], [1836, 0.014146905], [1837, 0.01193977], [1838, 0.9989311], [1839, 0.03386621], [1840, 0.0015771489], [1841, 0.005398813], [1842, 0.0034850866], [1843, 0.998998], [1844, 0.009068538], [1845, 0.0050218147], [1846, 0.0070978156], [1847, 0.0011201159], [1848, 0.019773602], [1849, 0.047698613], [1850, 0.7009641], [1851, 0.0032578043], [1852, 0.001688592], [1853, 0.015987955], [1854, 0.013840467], [1855, 0.0010290165], [1856, 0.99826306], [1857, 0.002202126], [1858, 0.9985776], [1859, 0.9976928], [1860, 0.9990963], [1861, 0.0030597914], [1862, 0.0015771489], [1863, 0.013515126], [1864, 0.008575429], [1865, 0.0014014316], [1866, 0.0019408255], [1867, 0.00041672666], [1868, 0.0009504732], [1869, 0.0005507565], [1870, 0.9990545], [1871, 0.0007441878], [1872, 0.55967796], [1873, 0.001688592], [1874, 0.9981713], [1875, 0.99907506], [1876, 0.9990706], [1877, 0.00063790486], [1878, 0.00086764357], [1879, 0.007609891], [1880, 0.99893326], [1881, 0.9989436], [1882, 0.0073340666], [1883, 0.0010625883], [1884, 0.0058090137], [1885, 0.0006277374], [1886, 0.0027038145], [1887, 0.96467584], [1888, 0.0015771489], [1889, 0.74956733], [1890, 0.0013437759], [1891, 0.0049232207], [1892, 0.00460205], [1893, 0.9982509], [1894, 0.002267075], [1895, 0.99908423], [1896, 0.0071541634], [1897, 0.0006794807], [1898, 0.97938776], [1899, 0.9979189], [1900, 0.0013659161], [1901, 0.016732711], [1902, 0.0053844554], [1903, 0.9990877], [1904, 0.00648453], [1905, 0.39999467], [1906, 0.0026228814], [1907, 0.08103358], [1908, 0.02504305], [1909, 0.0028047988], [1910, 0.668534], [1911, 0.054360162], [1912, 0.9944072], [1913, 0.00043441882], [1914, 0.0015355957], [1915, 0.9971902], [1916, 0.0012184341], [1917, 0.99847597], [1918, 0.0010931352], [1919, 0.97356546], [1920, 0.0132796215], [1921, 0.01742036], [1922, 0.0008288677], [1923, 0.0025878833], [1924, 0.0015555116], [1925, 0.0024745844], [1926, 0.99870217], [1927, 0.34519503], [1928, 0.001909834], [1929, 0.0014219689], [1930, 0.0012461643], [1931, 0.044826552], [1932, 0.9986732], [1933, 0.03597001], [1934, 0.0069134366], [1935, 0.001248625], [1936, 0.0060284226], [1937, 0.86026734], [1938, 0.9989901], [1939, 0.0016977667], [1940, 0.0015090328], [1941, 0.9989907], [1942, 0.010080794], [1943, 0.28241295], [1944, 0.0019525477], [1945, 0.9989704], [1946, 0.99906033], [1947, 0.9990834], [1948, 0.025753452], [1949, 0.5012886], [1950, 0.99201596], [1951, 0.008977997], [1952, 0.0029266009], [1953, 0.99899477], [1954, 0.99762577], [1955, 0.001203921], [1956, 0.050283432], [1957, 0.9988275], [1958, 0.056998923], [1959, 0.008198717], [1960, 0.006970245], [1961, 0.000736297], [1962, 0.9990251], [1963, 0.0006560536], [1964, 0.0015771489], [1965, 0.99905735], [1966, 0.0021774273], [1967, 0.0017491742], [1968, 0.01663538], [1969, 0.017771231], [1970, 0.14526212], [1971, 0.0022378669], [1972, 0.0025485053], [1973, 0.003916901], [1974, 0.7883874], [1975, 0.00062549306], [1976, 0.0075535555], [1977, 0.014997009], [1978, 0.053005517], [1979, 0.0065235095], [1980, 0.007809143], [1981, 0.9988961], [1982, 0.0015771489], [1983, 0.99905914], [1984, 0.0058347415], [1985, 0.0015771481], [1986, 0.99895144], [1987, 0.0007012636], [1988, 0.98984295], [1989, 0.9990646], [1990, 0.99818075], [1991, 0.0013775541], [1992, 0.013112383], [1993, 0.0015771481], [1994, 0.00052940554], [1995, 0.0011254733], [1996, 0.0016885927], [1997, 0.0010597259], [1998, 0.03235493], [1999, 0.9985273], [2000, 0.0004860186]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kDozkVphv2-u"},"source":["save_prediction_to_csv(ret_res, \"pred3_19_1st\")"],"execution_count":null,"outputs":[]}]}