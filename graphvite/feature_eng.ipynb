{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOcEJLpBsI16"
   },
   "source": [
    "### Feature Engineering\n",
    "##### It's a simple step, extract all edges in the train.txt document. Then save all edges line by line in edges.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2021,
     "status": "ok",
     "timestamp": 1617771795130,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "ilaAal9brafl",
    "outputId": "45c7e880-7419-4319-d2e7-de5cfdb9b33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 54  self-circles.\n"
     ]
    }
   ],
   "source": [
    "# Candidate1: self-circles only exists for non-existence nodes in test-public.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "nodes = []\n",
    "with open('data/train.txt', 'r') as f, open('data/edges.txt', 'w') as o, open('data/test-public.csv', 'r') as t:\n",
    "    training_data = f.readlines()\n",
    "    for line in training_data:\n",
    "        l = line.split() # each line ['str1', 'str2'] \n",
    "        for i in range(len(l)):\n",
    "            nodes.append(l[i])\n",
    "            for j in range(len(l)):\n",
    "                if i!=j:\n",
    "                    o.write(f'{l[i]} {l[j]}\\n')\n",
    "    setOfNodes = set(nodes)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    test_data = t.readlines()\n",
    "    test_data = test_data[1:]\n",
    "\n",
    "    for line in test_data:\n",
    "        line = line[:len(line) -1]\n",
    "        l = line.split(',')\n",
    "        for i in range(1, len(l)):\n",
    "            if l[i] not in setOfNodes:\n",
    "                o.write(f'{l[i]} {l[i]}\\n')\n",
    "                count+=1\n",
    "    print('Added', count, ' self-circles.')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1617771800483,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "2xsSrKUfrafq",
    "outputId": "e3978823-7edc-4903-9ef9-16f33759c620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59294 data/edges.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Check the size of results. \n",
    "\n",
    "!wc -l data/edges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1617771802449,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "0V8ucchqTxzp",
    "outputId": "6e6c5baf-06a6-484c-8411-4a04511c4c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes without duplicate:  3767\n",
      "edges without duplicate:  32070\n"
     ]
    }
   ],
   "source": [
    "# Candidate2: No duplicated edges, no test-public consideration\n",
    "nodes = []\n",
    "edges = []\n",
    "with open('data/train.txt', 'r') as f, open('data/edges_no_duplicate.txt', 'w') as o:\n",
    "    training_data = f.readlines()\n",
    "    for line in training_data:\n",
    "        l = line.split() # each line ['str1', 'str2'] \n",
    "        for i in range(len(l)):\n",
    "            nodes.append(l[i])\n",
    "            for j in range(len(l)):\n",
    "                if i!=j:\n",
    "                    #o.write(f'{l[i]} {l[j]}\\n')\n",
    "                    edges.append((int(l[i]), int(l[j])))\n",
    "\n",
    "    setOfNodes = set(nodes)\n",
    "    setOfEdges = set(edges)\n",
    "    print('nodes without duplicate: ', len(setOfNodes))\n",
    "    print('edges without duplicate: ', len(setOfEdges))\n",
    "          \n",
    "    no_dup_edges = list(setOfEdges)\n",
    "    for elem in no_dup_edges:\n",
    "        o.write(f'{elem[0]} {elem[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1617766145402,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "8cajiZyEYBYv",
    "outputId": "5c156a77-55dc-4940-cff4-0db17e0e05fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32070 data/edges_no_duplicate.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/edges_no_duplicate.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting graph data/edges.txt into train8.txt, test2.txt\n"
     ]
    }
   ],
   "source": [
    "# Split validation set\n",
    "import numpy as np\n",
    "\n",
    "def link_prediction_split(graph_file, files, portions):\n",
    "    \"\"\"\n",
    "    Divide a normal graph into a train split and several test splits for link prediction use.\n",
    "    Each test split contains half true and half false edges.\n",
    "\n",
    "    Parameters:\n",
    "        graph_file (str): graph file\n",
    "        files (list of str): file names,\n",
    "            the first file is treated as train file\n",
    "        portions (list of float): split portions\n",
    "    \"\"\"\n",
    "    assert len(files) == len(portions)\n",
    "    print(f\"splitting graph {graph_file} into {', '.join([f for f in files])}\")\n",
    "    np.random.seed(1024)\n",
    "\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    portions = np.cumsum(portions, dtype=np.float32) / np.sum(portions)\n",
    "    files = [open(file, \"w\") for file in files]\n",
    "    num_edges = [0] * len(files)\n",
    "    with open(graph_file, \"r\") as fin:\n",
    "        for line in fin:\n",
    "            u, v = line.split()[:2]\n",
    "            nodes.update([u, v])\n",
    "            edges.add((u, v))\n",
    "            i = np.searchsorted(portions, np.random.rand())\n",
    "            if i == 0:\n",
    "                files[i].write(line)\n",
    "            else:\n",
    "                files[i].write(f\"{u}\\t{v}\\t1\\n\")\n",
    "            num_edges[i] += 1\n",
    "\n",
    "    nodes = list(nodes)\n",
    "    for file, num_edge in zip(files[1:], num_edges[1:]):\n",
    "        for _ in range(num_edge):\n",
    "            valid = False\n",
    "            while not valid:\n",
    "                u = nodes[int(np.random.rand() * len(nodes))]\n",
    "                v = nodes[int(np.random.rand() * len(nodes))]\n",
    "                valid = u != v and (u, v) not in edges and (v, u) not in edges\n",
    "            file.write(f\"{u}\\t{v}\\t0\\n\")\n",
    "    for file in files:\n",
    "        file.close()\n",
    "\n",
    "link_prediction_split('data/edges.txt', ['train8.txt', 'test2.txt'], [8, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEzlCx4zs7cU"
   },
   "source": [
    "### NOTES On Colab\n",
    "#### When you run your code on colab you need to load the goole's virtual drive. Run the following blocks to load drive and 'cd' to the current path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19224,
     "status": "ok",
     "timestamp": 1617771789428,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "95DpLR0_rpE1",
    "outputId": "8d0054b9-1b41-4c70-b0e0-3347a6cc8419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1617771791131,
     "user": {
      "displayName": "gong shuzhi",
      "photoUrl": "",
      "userId": "05618588835000088934"
     },
     "user_tz": -600
    },
    "id": "aQwOsC6crafr",
    "outputId": "833aea1b-8ac2-413d-fc38-7541d5d03fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Graph_Link_Prediction/graphvite\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Graph_Link_Prediction/graphvite/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "feature_eng.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
